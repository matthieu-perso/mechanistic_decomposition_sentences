{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b3c3cef3-5f11-4772-b00a-935e7f01e129",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MODELS = [\n",
    "    \"Alibaba-NLP/gte-large-en-v1.5\",\n",
    "    \"intfloat/multilingual-e5-large\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "]\n",
    "\n",
    "DATA_PATH = '../data/sentence-embeddings'\n",
    "RELATIONS_JSON_PATH = '../data/relations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c6db848-6e01-4555-b0c0-4141aab51dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RELATIONS_JSON_PATH, 'r') as f:\n",
    "    relations = json.load(f)['spatial_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13dd5040-8f7d-4046-a718-ffcd6eaf621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_lookup(relations):\n",
    "    relations_lookup = {}\n",
    "    for category, category_pairs in relations.items():\n",
    "        for first, second in category_pairs:\n",
    "            relations_lookup[first] = {'category': category, 'opposite': second, 'position': 0}\n",
    "            relations_lookup[second] = {'category': category, 'opposite': first, 'position': 1}\n",
    "    return relations_lookup\n",
    "\n",
    "relations_lookup = get_relations_lookup(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1931dbfc-63ae-45fc-b782-0533ef235dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_for_model(model_name, relations_lookup):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    raw_data = torch.load(f'{DATA_PATH}/{model_name.replace(\"/\", \"_\")}.pt', weights_only=False)\n",
    "    for data_point in raw_data:\n",
    "        embeddings.append(data_point['embedding'])\n",
    "        labels.append(data_point['relation'])\n",
    "    return np.array(embeddings), np.array(labels).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd5ca67f-05f5-4ed5-a72e-30397f85e958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probe for Alibaba-NLP/gte-large-en-v1.5...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 1.00\n",
      "Training probe for intfloat/multilingual-e5-large...\n",
      "Accuracy for intfloat/multilingual-e5-large: 1.00\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2...\n",
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 1.00\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 1.00\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "models = {}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "for model_name in MODELS:\n",
    "    print(f\"Training probe for {model_name}...\")\n",
    "    X, y = load_embeddings_for_model(model_name, relations_lookup)\n",
    "    y_encoded = one_hot_encoder.fit_transform(y).todense()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2) \n",
    "\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    # Train probe\n",
    "    clf = MLPClassifier(activation='identity')\n",
    "    clf.fit(X_train, y_train)\n",
    "    models[model_name] = clf\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    results[model_name] = accuracy\n",
    "    print(f\"Accuracy for {model_name}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "029ec1f1-9386-464d-853c-8fa6facadfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_for_model_with_category_labels(model_name, relations_lookup):\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    raw_data = torch.load(f'{DATA_PATH}/{model_name.replace(\"/\", \"_\")}.pt', weights_only=False)\n",
    "    for data_point in raw_data:\n",
    "        embeddings.append(data_point['embedding'])\n",
    "        relation = data_point['relation']\n",
    "        category = relations_lookup[relation]['category']\n",
    "        position = relations_lookup[relation]['position']\n",
    "        labels.append(f'{category}-{position}')\n",
    "    return np.array(embeddings), np.array(labels).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e0344fc9-aca6-4da0-b6ba-787e96cf7495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probe for Alibaba-NLP/gte-large-en-v1.5...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 1.00\n",
      "Training probe for intfloat/multilingual-e5-large...\n",
      "Accuracy for intfloat/multilingual-e5-large: 1.00\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2...\n",
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 1.00\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 1.00\n"
     ]
    }
   ],
   "source": [
    "category_results = {}\n",
    "category_models = {}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "for model_name in MODELS:\n",
    "    print(f\"Training probe for {model_name}...\")\n",
    "    X, y = load_embeddings_for_model_with_category_labels(model_name, relations_lookup)\n",
    "    y_encoded = one_hot_encoder.fit_transform(y).todense()\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2) \n",
    "\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    \n",
    "    # Train probe\n",
    "    clf = MLPClassifier(activation='identity')\n",
    "    clf.fit(X_train, y_train)\n",
    "    category_models[model_name] = clf\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    category_results[model_name] = accuracy\n",
    "    print(f\"Accuracy for {model_name}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a551636f-2844-451d-9d4c-c547fb132aac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mMODELS\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MODELS' is not defined"
     ]
    }
   ],
   "source": [
    "MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0a683e-c229-4390-8a8e-d583f29c8202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
