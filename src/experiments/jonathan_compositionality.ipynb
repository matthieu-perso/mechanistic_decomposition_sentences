{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.3 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.10/3.10.15/Frameworks/Python.framework/Versions/3.10/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/qr/lzt26vs51rz7c5d6967grqnc0000gn/T/ipykernel_26988/3609579611.py\", line 2, in <module>\n",
      "    import torch\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MODELS = [\n",
    "    \"Alibaba-NLP/gte-large-en-v1.5\",\n",
    "    \"intfloat/multilingual-e5-large\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'https://huggingface.co/datasets/matthieunlp/spatial_geometry/resolve/main/src/data/sentence-embeddings'\n",
    "RELATIONS_JSON_PATH = '../data/relations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RELATIONS_JSON_PATH, 'r') as f:\n",
    "    relations = json.load(f)['spatial_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_lookup(relations):\n",
    "    relations_lookup = {}\n",
    "    for category, category_pairs in relations.items():\n",
    "        for first, second in category_pairs:\n",
    "            relations_lookup[first] = {'category': category, 'opposite': second, 'position': 0}\n",
    "            relations_lookup[second] = {'category': category, 'opposite': first, 'position': 1}\n",
    "    return relations_lookup\n",
    "\n",
    "relations_lookup = get_relations_lookup(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_for_model(model_name, datapoint='relation'):\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    url = f'{DATA_PATH}/{model_name.replace(\"/\", \"_\")}.pt'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    raw_data = torch.load(BytesIO(response.content), weights_only=False)\n",
    "    \n",
    "    for data_point in raw_data:\n",
    "        embeddings.append(data_point['embedding'])\n",
    "        labels.append(data_point[datapoint])\n",
    "    return np.array(embeddings), np.array(labels).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probes for all relations\n",
    "\n",
    "We expect that we will find linear relations, but we also have to isolate the syntaxic elements. \n",
    "\n",
    "We train a couple series of probes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multitask_probe_for_datapoint(results_dict, models_dict, encoder):\n",
    "    for model_name in MODELS:\n",
    "        print(f\"Training multitask probe for {model_name} on all datapoints...\")\n",
    "        X, y_relation = load_embeddings_for_model(model_name, datapoint='relation')\n",
    "        X, y_subject = load_embeddings_for_model(model_name, datapoint='subject')\n",
    "        X, y_object = load_embeddings_for_model(model_name, datapoint='object')\n",
    "\n",
    "        # One-hot encode all labels together\n",
    "        y_combined = np.column_stack([y_relation, y_subject, y_object])  # Stack labels side by side\n",
    "        y_encoded = encoder.fit_transform(y_combined).todense()\n",
    "        \n",
    "        y_encoded = encoder.fit_transform(y).todense()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        # Train probe\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(), \n",
    "                            early_stopping=True, \n",
    "                            activation='identity')\n",
    "        clf.fit(X_train, y_train)\n",
    "        models_dict[model_name] = clf\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_dict[model_name] = accuracy\n",
    "        print(f\"Accuracy for {model_name}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probe for Alibaba-NLP/gte-large-en-v1.5 on relation...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 1.00\n",
      "Training probe for intfloat/multilingual-e5-large on relation...\n",
      "Accuracy for intfloat/multilingual-e5-large: 1.00\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2 on relation...\n",
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 0.99\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2 on relation...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 1.00\n",
      "Training probe for Alibaba-NLP/gte-large-en-v1.5 on subject...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 1.00\n",
      "Training probe for intfloat/multilingual-e5-large on subject...\n",
      "Accuracy for intfloat/multilingual-e5-large: 0.99\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2 on subject...\n",
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 1.00\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2 on subject...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 1.00\n",
      "Training probe for Alibaba-NLP/gte-large-en-v1.5 on object...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 0.99\n",
      "Training probe for intfloat/multilingual-e5-large on object...\n",
      "Accuracy for intfloat/multilingual-e5-large: 0.98\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2 on object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 0.98\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2 on object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathanmichala/All Documents/spatial_geometry/spatgeo-env/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 0.97\n",
      "Training multitask probe for Alibaba-NLP/gte-large-en-v1.5 on all datapoints...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m\n\u001b[1;32m     39\u001b[0m train_probe_for_datapoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubject\u001b[39m\u001b[38;5;124m'\u001b[39m, subject_results, subject_models, subject_one_hot_encoder)\n\u001b[1;32m     40\u001b[0m train_probe_for_datapoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m, object_results, object_models, object_one_hot_encoder)\n\u001b[0;32m---> 41\u001b[0m \u001b[43mtrain_multitask_probe_for_datapoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmultitask_results\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultitask_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultitask_one_hot_encoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m, in \u001b[0;36mtrain_multitask_probe_for_datapoint\u001b[0;34m(results_dict, models_dict, encoder)\u001b[0m\n\u001b[1;32m      9\u001b[0m y_combined \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcolumn_stack([y_relation, y_subject, y_object])  \u001b[38;5;66;03m# Stack labels side by side\u001b[39;00m\n\u001b[1;32m     10\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(y_combined)\u001b[38;5;241m.\u001b[39mtodense()\n\u001b[0;32m---> 12\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43my\u001b[49m)\u001b[38;5;241m.\u001b[39mtodense()\n\u001b[1;32m     13\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y_encoded, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     15\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "def train_probe_for_datapoint(datapoint, results_dict, models_dict, encoder):\n",
    "    for model_name in MODELS:\n",
    "        print(f\"Training probe for {model_name} on {datapoint}...\")\n",
    "        X, y = load_embeddings_for_model(model_name, datapoint=datapoint)\n",
    "        y_encoded = encoder.fit_transform(y).todense()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        # Train probe\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(), early_stopping=True, activation='identity')\n",
    "        clf.fit(X_train, y_train)\n",
    "        models_dict[model_name] = clf\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_dict[model_name] = accuracy\n",
    "        print(f\"Accuracy for {model_name}: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "results = {}\n",
    "models = {}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "subject_results = {}\n",
    "subject_models = {}\n",
    "subject_one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "object_results = {}\n",
    "object_models = {}\n",
    "object_one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "multitask_results = {}\n",
    "multitask_models = {}\n",
    "multitask_one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "train_probe_for_datapoint('relation', results, models, one_hot_encoder)\n",
    "train_probe_for_datapoint('subject', subject_results, subject_models, subject_one_hot_encoder)\n",
    "train_probe_for_datapoint('object', object_results, object_models, object_one_hot_encoder)\n",
    "train_multitask_probe_for_datapoint(multitask_results, multitask_models, multitask_one_hot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class PickleSaver:\n",
    "    def __init__(self, data, filename):\n",
    "        self.data = data\n",
    "        self.filename = filename\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.filename, 'wb') as f:\n",
    "            pickle.dump(self.data, f)\n",
    "\n",
    "# Create instances of PickleSaver for each data object\n",
    "pickle_savers = [\n",
    "    PickleSaver(results, 'results.pkl'),\n",
    "    PickleSaver(models, 'models.pkl'),\n",
    "    PickleSaver(one_hot_encoder, 'one_hot_encoder.pkl'),\n",
    "    PickleSaver(subject_results, 'subject_results.pkl'),\n",
    "    PickleSaver(subject_models, 'subject_models.pkl'),\n",
    "    PickleSaver(subject_one_hot_encoder, 'subject_one_hot_encoder.pkl'),\n",
    "    PickleSaver(object_results, 'object_results.pkl'),\n",
    "    PickleSaver(object_models, 'object_models.pkl'),\n",
    "    PickleSaver(object_one_hot_encoder, 'object_one_hot_encoder.pkl'),\n",
    "    PickleSaver(multitask_results, 'multitask_results.pkl'),\n",
    "    PickleSaver(multitask_models, 'multitask_models.pkl'),\n",
    "    PickleSaver(multitask_one_hot_encoder, 'multitask_one_hot_encoder.pkl')\n",
    "]\n",
    "\n",
    "# Save all data using the PickleSaver instances\n",
    "for saver in pickle_savers:\n",
    "    saver.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding all the elements\n",
    "\n",
    "We then build a dictionnary with the representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation between subject and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model: Alibaba-NLP/gte-large-en-v1.5\n",
      "Processing model: intfloat/multilingual-e5-large\n",
      "Processing model: sentence-transformers/all-mpnet-base-v2\n",
      "Processing model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Processing subject model: Alibaba-NLP/gte-large-en-v1.5\n",
      "Processing subject model: intfloat/multilingual-e5-large\n",
      "Processing subject model: sentence-transformers/all-mpnet-base-v2\n",
      "Processing subject model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Processing object model: Alibaba-NLP/gte-large-en-v1.5\n",
      "Processing object model: intfloat/multilingual-e5-large\n",
      "Processing object model: sentence-transformers/all-mpnet-base-v2\n",
      "Processing object model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "relation_representations = {}\n",
    "for model_name, clf in models.items():\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "    weights = clf.coefs_[0]\n",
    "    class_names = one_hot_encoder.get_feature_names_out()\n",
    "    relation_representations[model_name] = {\n",
    "        class_name.replace('x0_', ''): weights[:, i]\n",
    "        for i, class_name in enumerate(class_names)\n",
    "    }\n",
    "\n",
    "subject_class_representations = {}\n",
    "for model_name, clf in subject_models.items():\n",
    "    print(f\"Processing subject model: {model_name}\")\n",
    "    weights = clf.coefs_[0]\n",
    "    class_names = subject_one_hot_encoder.get_feature_names_out()\n",
    "    subject_class_representations[model_name] = {\n",
    "        class_name.replace('x0_', ''): weights[:, i]\n",
    "        for i, class_name in enumerate(class_names)\n",
    "    }\n",
    "\n",
    "# For object models\n",
    "object_class_representations = {}\n",
    "for model_name, clf in object_models.items():\n",
    "    print(f\"Processing object model: {model_name}\")\n",
    "    weights = clf.coefs_[0]\n",
    "    class_names = object_one_hot_encoder.get_feature_names_out()\n",
    "    object_class_representations[model_name] = {\n",
    "        class_name.replace('x0_', ''): weights[:, i]\n",
    "        for i, class_name in enumerate(class_names)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                model_name  \\\n",
      "0            Alibaba-NLP/gte-large-en-v1.5   \n",
      "1           intfloat/multilingual-e5-large   \n",
      "2  sentence-transformers/all-mpnet-base-v2   \n",
      "3   sentence-transformers/all-MiniLM-L6-v2   \n",
      "\n",
      "                                  relation_embedding  \\\n",
      "0  {'above': [0.5404442, 0.021074712, 0.062373973...   \n",
      "1  {'above': [2.1064472, -7.9145646, 5.6887074, 1...   \n",
      "2  {'above': [-0.3481432, 0.79766315, -3.3663204,...   \n",
      "3  {'above': [-11.558843, -6.817552, 2.4517975, -...   \n",
      "\n",
      "                                   subject_embedding  \\\n",
      "0  {'backpack': [0.49934778, 0.23872255, 0.046050...   \n",
      "1  {'backpack': [1.4004223, -2.450059, -2.2688642...   \n",
      "2  {'backpack': [0.19556403, 0.6709004, 1.932555,...   \n",
      "3  {'backpack': [7.311962, -3.0467436, 1.1281406,...   \n",
      "\n",
      "                                    object_embedding  \n",
      "0  {'backpack': [-0.28748193, -0.30316794, -0.330...  \n",
      "1  {'backpack': [-0.45119685, -1.0294902, -0.1519...  \n",
      "2  {'backpack': [-0.43592635, 1.6827934, -0.52899...  \n",
      "3  {'backpack': [-14.07742, 0.7779491, 2.782241, ...  \n"
     ]
    }
   ],
   "source": [
    "merged_class_representations = []\n",
    "\n",
    "for model_name in subject_class_representations.keys():\n",
    "    if model_name in object_class_representations:\n",
    "        merged_class_representations.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"relation_embedding\": relation_representations[model_name],\n",
    "            \"subject_embedding\": subject_class_representations[model_name],\n",
    "            \"object_embedding\": object_class_representations[model_name]\n",
    "        })\n",
    "\n",
    "merged_class_representations_df = pd.DataFrame(merged_class_representations)\n",
    "print(merged_class_representations_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5404442   0.02107471  0.06237397 ... -0.0452004   0.10567422\n",
      "  0.2879719 ]\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries to store embeddings for each model and class\n",
    "relations_by_model = {}\n",
    "subject_embeddings_by_model = {}\n",
    "object_embeddings_by_model = {}\n",
    "\n",
    "# Group by model name and class\n",
    "for model_name, row in merged_class_representations_df.iterrows():\n",
    "    relations_by_model[model_name] = row['relation_embedding']\n",
    "    subject_embeddings_by_model[model_name] = row['subject_embedding']\n",
    "    object_embeddings_by_model[model_name] = row['object_embedding']\n",
    "\n",
    "    \n",
    "    # Initialize dicts for new models\n",
    "    if model_name not in relations_by_model:\n",
    "        relations_by_model[model_name] = {}\n",
    "    if model_name not in subject_embeddings_by_model:\n",
    "        subject_embeddings_by_model[model_name] = {}\n",
    "    if model_name not in object_embeddings_by_model:\n",
    "        object_embeddings_by_model[model_name] = {}\n",
    "    \n",
    "    # Store all class representations\n",
    "    for class_name, relation_embedding in row['relation_embedding'].items():\n",
    "        relations_by_model[model_name][class_name] = relation_embedding\n",
    "    for class_name, subject_embedding in row['subject_embedding'].items():\n",
    "        subject_embeddings_by_model[model_name][class_name] = subject_embedding\n",
    "    for class_name, object_embedding in row['object_embedding'].items():\n",
    "        object_embeddings_by_model[model_name][class_name] = object_embedding\n",
    "\n",
    "# Usage case\n",
    "\n",
    "# Get embeddings for a specific model and class\n",
    "model_name = 0\n",
    "class_name = 'above'\n",
    "relation_embedding = relations_by_model[model_name][class_name]\n",
    "print(relation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          table_sentence\n",
      "0           The table is above the lamp.\n",
      "1            The table is over the lamp.\n",
      "2       The table is on top of the lamp.\n",
      "3     The table is higher than the lamp.\n",
      "4  The table is elevated above the lamp.\n",
      "                          chair_sentence\n",
      "0           The chair is above the lamp.\n",
      "1            The chair is over the lamp.\n",
      "2       The chair is on top of the lamp.\n",
      "3     The chair is higher than the lamp.\n",
      "4  The chair is elevated above the lamp.\n"
     ]
    }
   ],
   "source": [
    "# read generated_sentences.csv\n",
    "df = pd.read_csv(\"../../generated_sentences.csv\")\n",
    "\n",
    "# find sentences with table as subject\n",
    "table_sentences = df[df['subject'] == 'table']\n",
    "\n",
    "# find sentences with chair as subject\n",
    "chair_sentences = df[df['subject'] == 'chair']\n",
    "\n",
    "# Create X and y such that X are the table sentences, but y are the corresponding chair sentences\n",
    "# The sentences should be identical except for the subject\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for table_sentence in table_sentences['sentence']:\n",
    "    corresponding_chair_sentence = table_sentence.replace('table', 'chair')\n",
    "    if corresponding_chair_sentence in chair_sentences['sentence'].values:\n",
    "        X.append(table_sentence)\n",
    "        y.append(corresponding_chair_sentence)\n",
    "\n",
    "# Convert X and y to DataFrame for better visualization\n",
    "X_df = pd.DataFrame(X, columns=['table_sentence'])\n",
    "y_df = pd.DataFrame(y, columns=['chair_sentence'])\n",
    "\n",
    "# Display the DataFrames\n",
    "print(X_df.head())\n",
    "print(y_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ../data/Alibaba-NLP_gte-large-en-v1.5.pt!\n",
      "Loaded data type: <class 'list'>\n",
      "List length: 142100\n",
      "First item: {'sentence': 'The table is above the chair.', 'relation': 'above', 'subject': 'table', 'object': 'chair', 'embedding': array([ 0.32811892,  0.24800315,  0.28813255, ..., -0.2839055 ,\n",
      "       -0.95515853, -0.04943762], shape=(1024,), dtype=float32)}\n",
      "Data loaded successfully from ../data/intfloat_multilingual-e5-large.pt!\n",
      "Loaded data type: <class 'list'>\n",
      "List length: 142100\n",
      "First item: {'sentence': 'The table is above the chair.', 'relation': 'above', 'subject': 'table', 'object': 'chair', 'embedding': array([ 0.02130731, -0.01715695, -0.0045109 , ..., -0.02039933,\n",
      "        0.0191653 , -0.02246715], shape=(1024,), dtype=float32)}\n",
      "Data loaded successfully from ../data/sentence-transformers_all-mpnet-base-v2.pt!\n",
      "Loaded data type: <class 'list'>\n",
      "List length: 142100\n",
      "First item: {'sentence': 'The table is above the chair.', 'relation': 'above', 'subject': 'table', 'object': 'chair', 'embedding': array([-1.66614745e-02, -3.60186510e-02,  4.49463632e-03,  2.21219044e-02,\n",
      "       -4.24099825e-02, -1.09645305e-02, -1.47783617e-02,  1.23334210e-02,\n",
      "        3.73249985e-02, -1.03487598e-03,  2.90104300e-02,  4.08091731e-02,\n",
      "        6.05765777e-03, -2.13450976e-02,  7.88072050e-02,  4.64153811e-02,\n",
      "        2.49462519e-02,  2.48961095e-02,  5.56159839e-02,  3.14854924e-03,\n",
      "       -1.84976086e-02, -1.50769949e-02, -2.98004542e-02, -2.15669498e-02,\n",
      "       -2.13993900e-02,  1.35948788e-02, -1.13080032e-02, -3.05861793e-03,\n",
      "       -2.66035572e-02,  5.28071858e-02,  1.64867323e-02, -3.22910910e-03,\n",
      "        2.45539322e-02, -2.05645990e-02,  1.69552368e-06,  3.44652869e-02,\n",
      "       -1.21028963e-02,  2.57013012e-02, -2.53768656e-02, -5.14687598e-02,\n",
      "        8.27728398e-03, -1.50484238e-02, -1.11318715e-02, -1.81556232e-02,\n",
      "        1.33923590e-02,  6.02288684e-03, -3.50191887e-03,  4.45144437e-02,\n",
      "       -5.45055568e-02, -7.18069822e-03, -9.33045894e-03,  6.31056651e-02,\n",
      "       -2.84844823e-02,  1.25449384e-02,  8.15381855e-02, -4.63231169e-02,\n",
      "       -3.80691923e-02,  2.79474817e-02, -2.63929740e-02,  1.93859953e-02,\n",
      "        3.47380787e-02, -2.31152750e-03, -3.72373988e-03, -2.53875591e-02,\n",
      "        4.91502360e-02,  1.18258484e-02, -6.24524467e-02,  8.45145956e-02,\n",
      "        5.78406453e-03,  9.41813807e-04,  4.05732431e-02,  9.41037573e-03,\n",
      "        7.29256822e-03,  3.99018638e-02,  6.23433553e-02,  2.40922198e-02,\n",
      "        1.47856129e-02,  6.78651547e-03,  8.89835209e-02, -4.42500748e-02,\n",
      "        7.38600036e-03,  3.21273170e-02, -4.86004986e-02,  2.13856474e-02,\n",
      "        1.06567899e-02, -9.81193315e-03, -2.52406392e-02, -1.52770700e-02,\n",
      "        1.12053026e-02, -3.58196609e-02,  7.70758763e-02,  8.25498253e-03,\n",
      "        4.80279438e-02,  1.09899314e-02, -2.06120964e-03, -1.03549520e-02,\n",
      "        4.47120816e-02,  4.67555374e-02,  1.39101315e-02, -5.35479747e-02,\n",
      "        1.19233780e-01,  5.20707220e-02,  8.24641585e-02, -1.42734060e-02,\n",
      "       -2.28947997e-02,  1.76319368e-02, -5.87981716e-02, -7.36511797e-02,\n",
      "       -3.28257941e-02,  6.42749891e-02, -7.67584075e-04, -1.97310895e-02,\n",
      "       -5.04040867e-02,  1.05155008e-02, -6.48656785e-02, -7.06591224e-03,\n",
      "        5.92292063e-02, -1.39927370e-02,  2.29662284e-02,  3.45831923e-02,\n",
      "       -8.25902727e-03,  5.93767948e-02, -2.60180645e-02,  3.76049168e-02,\n",
      "       -1.40270824e-02, -1.55591834e-02, -8.81915633e-03,  3.17952260e-02,\n",
      "        1.46615757e-02, -4.96284403e-02, -8.51893611e-03, -2.32313294e-02,\n",
      "        5.38649922e-03, -2.60532033e-02,  4.81318543e-03,  6.69407174e-02,\n",
      "       -2.69796569e-02,  6.16288558e-02,  9.25914720e-02,  1.20317622e-03,\n",
      "        2.70582363e-02,  2.72942390e-02,  1.21618072e-02,  1.13089746e-02,\n",
      "        3.43941487e-02, -2.95763668e-02,  4.87095043e-02, -8.61520413e-03,\n",
      "        6.51030801e-03,  2.35165507e-02,  1.26303714e-02,  2.60511525e-02,\n",
      "        4.81411926e-02,  2.81731300e-02,  2.26386506e-02,  9.35415272e-03,\n",
      "       -4.79547977e-02,  1.99153498e-02,  3.19580436e-02,  3.38827483e-02,\n",
      "       -2.86800079e-02,  3.01960716e-03, -3.62722650e-02, -1.50779588e-02,\n",
      "       -4.45791101e-03, -4.32762355e-02,  3.16668116e-02,  2.46963967e-02,\n",
      "       -3.73615250e-02,  2.47658584e-02, -7.07696304e-02, -4.61724624e-02,\n",
      "        2.84398235e-02,  1.31149575e-01,  2.03145333e-02, -2.37456799e-04,\n",
      "       -6.89833835e-02,  5.32832369e-02, -9.98085588e-02, -1.63890403e-02,\n",
      "       -3.84300202e-02,  1.48888109e-02, -4.83840180e-04,  3.04967482e-02,\n",
      "        1.76482461e-02, -2.41718329e-02, -4.19305079e-03, -1.59493163e-02,\n",
      "       -3.78998294e-02,  7.78176636e-03, -1.88585408e-02, -1.40291499e-02,\n",
      "       -5.30857220e-03, -5.96324960e-03, -1.53834571e-03, -7.73801096e-03,\n",
      "       -4.39936556e-02, -6.20925725e-02, -1.00697409e-02, -4.78567518e-02,\n",
      "       -6.03125952e-02, -1.99823752e-02, -1.91473938e-03,  5.09995334e-02,\n",
      "        1.77025527e-03, -3.06001958e-02,  3.32569005e-03,  7.53223291e-03,\n",
      "        9.14577469e-02,  8.20827764e-03, -1.68882869e-02, -9.99573898e-03,\n",
      "       -2.02617655e-03,  7.65432045e-02, -1.81161091e-02,  6.23397902e-02,\n",
      "       -2.44853552e-03,  6.39534369e-02, -2.19281167e-02, -1.06022591e-02,\n",
      "       -1.11912079e-02, -6.04338292e-03, -1.10472469e-02, -1.00194728e-02,\n",
      "        9.33552906e-03,  1.80640202e-02, -1.52002592e-02, -2.89464137e-03,\n",
      "        3.18677872e-02,  2.52392422e-03,  1.64919198e-02,  2.04856582e-02,\n",
      "        3.64732705e-02, -4.51390482e-02,  9.16596968e-03, -5.46066537e-02,\n",
      "       -1.15759827e-01,  1.99986063e-02, -3.58641781e-02, -5.42103536e-02,\n",
      "       -1.69225223e-02, -4.21732739e-02,  5.11685479e-03, -1.84123311e-02,\n",
      "        7.68219307e-02, -6.64723106e-03, -4.03995849e-02, -1.36459284e-02,\n",
      "       -2.91376803e-02,  8.53718631e-03,  7.49150990e-03,  4.94307168e-02,\n",
      "        5.43394089e-02, -1.69119202e-02, -2.07782350e-02,  2.25407612e-02,\n",
      "       -8.04391727e-02,  1.78084224e-02, -7.89269153e-03,  6.03447892e-02,\n",
      "       -1.86152048e-02, -2.22216286e-02,  2.27263030e-02,  1.81934629e-02,\n",
      "        3.36452834e-02, -2.76976470e-02,  2.13061664e-02, -6.10386655e-02,\n",
      "       -4.05158754e-03,  5.03343903e-03, -4.73394841e-02, -1.11223739e-02,\n",
      "       -9.33451299e-03,  1.86235067e-02, -8.51235446e-03, -2.84552183e-02,\n",
      "        9.55916650e-04, -2.20327433e-02,  4.36295709e-03,  1.86591933e-03,\n",
      "       -2.89817415e-02,  5.47353216e-02, -5.99232428e-02, -2.30322368e-02,\n",
      "        8.80220346e-03,  9.15153790e-03, -1.85568146e-02, -4.17824723e-02,\n",
      "        2.09934805e-02,  3.60621768e-03,  4.44869250e-02,  8.70440677e-02,\n",
      "        1.90792177e-02, -2.74984054e-02,  9.93041042e-03, -1.83361433e-02,\n",
      "        3.00702825e-02,  1.36680556e-02, -4.28014472e-02, -1.30962087e-02,\n",
      "       -6.51363749e-03,  2.56682187e-02, -5.19173406e-02, -1.45382108e-02,\n",
      "       -1.97051875e-02,  3.51702981e-02,  4.05034982e-02, -4.53948751e-02,\n",
      "        1.98036656e-02,  7.88208935e-03,  2.24076211e-02, -1.03451684e-02,\n",
      "        1.71897337e-02, -2.25129835e-02,  1.57994013e-02, -3.74217853e-02,\n",
      "       -1.03392974e-01, -1.44288084e-02, -6.06026649e-02, -6.90613687e-02,\n",
      "        1.15609309e-02,  3.18619423e-02, -1.55651104e-02, -2.01072749e-02,\n",
      "        2.69784611e-02,  5.01237102e-02,  3.31580713e-02,  2.92130206e-02,\n",
      "        4.98708710e-02, -4.13980149e-03, -2.66722012e-02, -8.26380774e-02,\n",
      "       -6.47731684e-03,  1.17773563e-03,  1.07805692e-02,  9.90737043e-03,\n",
      "       -2.11391542e-02, -4.62885201e-02, -3.16043086e-02,  2.95935422e-02,\n",
      "       -3.81582826e-02,  9.84996744e-03, -3.84263135e-03, -1.55505044e-02,\n",
      "        5.59651759e-03,  3.62664610e-02,  4.78141150e-03,  1.97551083e-02,\n",
      "       -2.82855686e-02, -4.59399745e-02, -1.78988203e-02,  7.75654837e-02,\n",
      "        3.81814549e-03,  3.01801395e-02, -6.17238246e-02,  3.25679481e-02,\n",
      "        1.14064943e-02,  3.04307733e-02, -3.78393456e-02, -4.76216991e-03,\n",
      "       -2.61262674e-02,  3.93414013e-02, -2.02549845e-02,  1.49524910e-02,\n",
      "       -1.57639310e-02,  4.14584465e-02,  1.56077845e-02,  2.54939813e-02,\n",
      "        5.55408150e-02,  9.49159637e-03, -6.39946237e-02,  3.93799059e-02,\n",
      "        1.32129835e-02,  3.72483879e-02,  8.32221657e-03, -3.03036738e-02,\n",
      "       -8.81726574e-03,  7.22600752e-03, -4.10152692e-03, -1.55683681e-02,\n",
      "        2.13751220e-03,  7.48040946e-03,  8.14425759e-03,  1.74429622e-02,\n",
      "       -8.36957097e-02, -3.00071537e-02, -1.21639231e-02, -8.41030702e-02,\n",
      "       -1.89585444e-02, -4.96094897e-02, -1.00012254e-02, -2.75543965e-02,\n",
      "       -4.72971387e-02,  6.09475560e-02, -5.46704838e-03,  1.96547862e-02,\n",
      "        7.06625953e-02,  5.16234599e-02,  9.33994260e-03,  9.84304305e-03,\n",
      "        2.52362099e-02,  2.93899588e-02,  3.45008820e-02, -1.57204624e-02,\n",
      "       -1.24238916e-02, -3.63947861e-02, -6.04658946e-03,  6.47126064e-02,\n",
      "        2.12559514e-02,  8.23368579e-02,  1.17895333e-02, -6.96891397e-02,\n",
      "        3.17800678e-02,  3.14170420e-02,  1.94845293e-02, -1.66895725e-02,\n",
      "        2.15018243e-02, -3.99917923e-02, -4.62871678e-02,  3.05307331e-03,\n",
      "        3.37496214e-02,  3.33348871e-03,  5.16297147e-02, -4.97348905e-02,\n",
      "        3.09804678e-02,  1.65060591e-02, -8.95292556e-04,  3.06076575e-02,\n",
      "       -1.29239156e-03,  3.55848186e-02,  1.47389118e-02, -4.22558077e-02,\n",
      "       -1.05290152e-02,  2.22334433e-02,  1.52797149e-02,  1.41431764e-01,\n",
      "       -1.91321014e-03, -4.64581437e-02,  9.16462019e-03, -4.24850993e-02,\n",
      "        4.34375666e-02,  1.74297206e-02, -1.16897644e-02,  9.92514193e-03,\n",
      "        5.29330000e-02, -5.76347485e-02, -2.30492726e-02, -2.09455859e-04,\n",
      "       -4.52497322e-03, -2.61503365e-02,  2.07979679e-02,  5.18860295e-02,\n",
      "       -6.22583739e-02, -1.98781285e-02, -3.24487798e-02,  1.66908849e-03,\n",
      "       -4.19897698e-02,  6.35381788e-02,  3.66171985e-03,  4.86837467e-03,\n",
      "       -1.13749569e-02,  6.74536219e-03, -4.00323458e-02,  3.60717401e-02,\n",
      "       -3.24318558e-02, -4.83670495e-02, -1.35690514e-02, -8.38137269e-02,\n",
      "        1.95608400e-02, -5.51319448e-04, -1.27575710e-01,  2.40778234e-02,\n",
      "        1.20959384e-03,  9.89705976e-03, -1.07640624e-02, -1.92101691e-02,\n",
      "       -3.04336138e-02, -4.14294042e-02,  5.45600615e-02,  2.01697908e-02,\n",
      "       -3.17736156e-02,  1.66098457e-02,  4.10969071e-02, -4.62992489e-02,\n",
      "        4.96183569e-03,  9.55122523e-04, -6.30644262e-02, -2.83934474e-02,\n",
      "        1.01805916e-02, -2.50561181e-02, -1.13629410e-02, -2.66692527e-02,\n",
      "       -1.14654517e-02,  4.68851253e-02,  1.71866231e-02,  5.05581386e-02,\n",
      "       -7.46269361e-04, -1.64018590e-02, -2.72441879e-02, -1.03933439e-01,\n",
      "       -5.35094040e-03,  4.50647883e-02,  6.43541990e-03,  5.58150038e-02,\n",
      "       -3.65288854e-02,  3.03088576e-02, -3.02103385e-02, -8.47488455e-03,\n",
      "       -3.87708247e-02, -5.73919527e-02, -1.72368076e-03,  9.22701806e-02,\n",
      "       -1.46675215e-03,  1.28456810e-02,  2.68141497e-02,  1.13131059e-02,\n",
      "       -4.58680689e-02, -1.99328586e-02, -1.31705906e-02,  6.09090477e-02,\n",
      "        4.28436371e-03,  3.49459760e-02, -3.60368676e-02,  8.91231932e-03,\n",
      "       -3.18685621e-02,  1.83681659e-02, -3.01052537e-02,  3.91191803e-02,\n",
      "        3.96699309e-02,  2.65226718e-02,  3.16449441e-02, -6.38912693e-02,\n",
      "        2.97533628e-02,  2.37842146e-02, -3.04897875e-02,  2.09523570e-02,\n",
      "       -1.96344536e-02, -5.77816814e-02, -1.93534829e-02, -1.14141719e-03,\n",
      "        6.58449531e-02, -1.20020136e-02, -5.54374009e-02,  4.53064963e-02,\n",
      "       -2.32114196e-02,  2.62771398e-02,  1.57283526e-02, -4.42624769e-05,\n",
      "        8.52278713e-03, -5.04419394e-02, -3.15850005e-02,  4.42766473e-02,\n",
      "        9.57677234e-03,  1.46205425e-02, -1.73643734e-02, -6.01081689e-33,\n",
      "       -4.75519858e-02,  5.63701754e-03, -3.52344150e-03, -5.73349409e-02,\n",
      "        5.92380646e-04,  2.39849556e-02, -4.91214059e-02, -8.69161636e-03,\n",
      "       -1.13620134e-02,  5.98117197e-03, -2.95607895e-02,  7.04113990e-02,\n",
      "        1.80013385e-02, -7.68015767e-03,  2.68440228e-02, -7.30224922e-02,\n",
      "       -3.07041593e-03,  8.96679354e-04,  6.58120140e-02,  2.24393997e-02,\n",
      "       -1.58452373e-02,  6.06628042e-03,  4.33249250e-02,  3.60531472e-02,\n",
      "        2.85756565e-03,  2.77273338e-02,  2.35982966e-02, -5.29066883e-02,\n",
      "        1.99510641e-02, -1.82169173e-02, -6.08504452e-02, -1.62056517e-02,\n",
      "       -1.60625353e-02,  4.44171019e-02, -3.81554081e-03,  7.66691417e-02,\n",
      "       -4.35574874e-02, -3.84920202e-02, -1.41613875e-02,  1.22360634e-02,\n",
      "       -5.38187549e-02, -2.16849279e-02, -1.45980222e-02, -1.20121951e-03,\n",
      "       -5.27000986e-02, -2.97604930e-02, -8.78636818e-03,  2.68506575e-02,\n",
      "       -6.09635608e-03,  3.01017594e-02,  2.75788959e-02, -3.26241739e-02,\n",
      "       -5.60416840e-02, -2.53218655e-02,  1.34128258e-02,  3.14914808e-02,\n",
      "        4.10225615e-02, -4.79947329e-02,  1.42175332e-02,  3.70066278e-02,\n",
      "       -4.18820344e-02, -3.91262434e-02,  3.82688758e-03, -3.49113755e-02,\n",
      "        1.47748282e-02,  2.91295387e-02,  2.24836990e-02,  7.12876022e-02,\n",
      "       -8.56757984e-02,  7.75189931e-03, -6.42741919e-02,  5.51342107e-02,\n",
      "        6.30615419e-03, -7.27323070e-02, -1.94296781e-02,  7.36009097e-03,\n",
      "        1.11980541e-02,  3.65057625e-02, -6.59362078e-02,  7.97878206e-02,\n",
      "        3.22634876e-02, -1.58866029e-02, -2.63652205e-02, -8.81148269e-04,\n",
      "        6.52565854e-03,  3.70010026e-02,  1.46862036e-02, -1.87123697e-02,\n",
      "       -2.47836988e-02, -2.50771269e-02,  6.22599088e-02, -6.80542812e-02,\n",
      "        1.16909323e-02, -1.77716184e-02, -2.85344925e-02,  4.06985544e-02,\n",
      "        4.13208157e-02, -4.16053310e-02,  1.18207717e-02,  8.18591379e-03,\n",
      "       -6.10210607e-03, -2.24447250e-03,  1.22328207e-03, -8.32987577e-03,\n",
      "       -3.81628703e-03,  1.20309489e-02, -3.80816832e-02, -1.23952068e-02,\n",
      "        2.51151975e-02, -1.96148325e-02, -6.06896430e-02,  3.12263221e-02,\n",
      "       -9.10345465e-03,  4.87500690e-02, -5.45269949e-03,  1.18817836e-02,\n",
      "       -9.11959447e-03,  7.22969845e-02,  4.76443768e-03,  4.33285125e-02,\n",
      "       -6.97915326e-04, -1.88667309e-02, -5.65939136e-02,  1.55071346e-02,\n",
      "        1.09581519e-02,  1.59511138e-02, -5.15036657e-02, -2.22755056e-02,\n",
      "        1.64669976e-02, -3.13693061e-02,  2.30851620e-02, -1.36136953e-02,\n",
      "        2.20378652e-07,  3.43998857e-02, -9.48323589e-03,  1.13785220e-02,\n",
      "        2.72645545e-03,  1.53044229e-02, -4.24756743e-02,  2.02732012e-02,\n",
      "        1.16364295e-02, -7.17257441e-04, -3.46499123e-02,  2.36752685e-02,\n",
      "       -8.69779196e-03,  1.52713628e-02, -3.75326797e-02,  2.18393803e-02,\n",
      "       -9.43808351e-04, -5.87542318e-02, -2.74913609e-02, -2.01299805e-02,\n",
      "        1.30291013e-02, -4.72233556e-02, -8.63639172e-03, -2.84631420e-02,\n",
      "       -3.29888090e-02, -6.62492216e-02, -3.22837755e-02,  6.37654681e-03,\n",
      "       -1.10538334e-01, -1.18271494e-02, -1.01385796e-02,  5.40584465e-03,\n",
      "        2.05138084e-02,  1.35612143e-02,  2.87238806e-02, -2.62776036e-02,\n",
      "       -1.43140173e-02,  9.61002521e-03, -1.21688144e-03, -2.20171697e-02,\n",
      "        6.65825531e-02,  1.15344347e-02, -3.62777226e-02, -1.33654959e-02,\n",
      "        2.76211165e-02,  6.48213476e-02, -5.36289886e-02,  2.59678718e-02,\n",
      "        3.15261353e-03, -1.84738508e-03,  4.16320451e-02,  4.04315209e-03,\n",
      "        2.74817250e-03,  2.80293133e-02,  1.37973139e-02, -1.73022766e-02,\n",
      "       -3.32010053e-02,  9.29936650e-04,  2.47656498e-02,  4.65006754e-02,\n",
      "        7.86796436e-02, -2.39876099e-02,  4.07853127e-02,  3.72723490e-02,\n",
      "       -7.06125200e-02, -4.58797021e-03,  2.39977837e-02, -6.09203465e-02,\n",
      "        1.11245525e-34,  2.78499885e-03, -3.42481397e-02,  5.34407385e-02,\n",
      "        1.23784756e-02,  2.79000830e-02, -1.34190721e-02,  6.33449778e-02,\n",
      "       -3.17036593e-03, -1.39456522e-02, -2.37984769e-02, -6.05068207e-02],\n",
      "      dtype=float32)}\n",
      "Data loaded successfully from ../data/sentence-transformers_all-MiniLM-L6-v2.pt!\n",
      "Loaded data type: <class 'list'>\n",
      "List length: 142100\n",
      "First item: {'sentence': 'The table is above the chair.', 'relation': 'above', 'subject': 'table', 'object': 'chair', 'embedding': array([ 3.31653394e-02,  7.28241354e-03, -7.31046870e-02, -3.67850736e-02,\n",
      "       -3.51810530e-02,  3.92799191e-02,  2.37436704e-02, -5.24706533e-03,\n",
      "        5.02609722e-02,  4.37820405e-02,  5.32043986e-02, -3.25076561e-03,\n",
      "        6.30042031e-02, -2.94250250e-02, -3.85113358e-02, -4.48140018e-02,\n",
      "        4.72267084e-02,  8.07299837e-03, -7.39043579e-04,  5.55362329e-02,\n",
      "       -1.17338086e-02,  3.30306068e-02,  3.84097658e-02, -1.70371588e-02,\n",
      "        1.41698122e-02, -3.82575020e-02,  4.70589735e-02, -3.26507129e-02,\n",
      "       -4.81344983e-02, -2.42122281e-02, -2.93514710e-02, -4.36589792e-02,\n",
      "        1.17120482e-02, -1.16237644e-02, -8.19648653e-02, -9.86989960e-03,\n",
      "       -4.36491566e-03, -1.98171418e-02,  2.36214381e-02,  1.62884854e-02,\n",
      "       -1.33848161e-01, -4.57683019e-02,  1.24671578e-03,  1.49421059e-02,\n",
      "       -2.76116226e-02,  2.65348945e-02, -7.88682792e-03, -8.65184888e-02,\n",
      "       -4.97281738e-02,  5.23552625e-03, -5.79705797e-02,  6.05334640e-02,\n",
      "        3.33944522e-02,  1.37824574e-02,  1.77662564e-03,  1.00060068e-01,\n",
      "        1.70589481e-02, -9.68620777e-02,  5.85477939e-03, -9.17408895e-03,\n",
      "       -3.81368399e-02, -4.21776809e-02,  4.41879220e-02,  1.10783242e-02,\n",
      "       -6.47820979e-02,  3.71612385e-02, -3.21402377e-03, -1.05537787e-01,\n",
      "       -7.63281062e-02,  1.65578611e-02,  3.14743780e-02,  6.09230762e-03,\n",
      "        1.94929149e-02, -3.01405583e-02, -6.82962919e-03, -6.24015629e-02,\n",
      "        4.18469869e-03, -4.40408755e-03,  7.28850886e-02,  2.27440242e-03,\n",
      "        3.08161527e-02,  5.77927344e-02,  2.86091659e-02,  2.41386443e-02,\n",
      "       -1.33599387e-02,  5.78268096e-02,  4.27570716e-02,  4.41702381e-02,\n",
      "       -1.27556473e-01, -7.02455714e-02,  7.31570050e-02,  2.37525925e-02,\n",
      "       -7.14076012e-02,  4.98794541e-02, -1.01969302e-01,  3.73410545e-02,\n",
      "        5.67975231e-02,  2.63904613e-02, -6.95101102e-04,  6.01957254e-02,\n",
      "        7.91862980e-03,  5.09177856e-02, -3.15453932e-02,  6.71625882e-02,\n",
      "       -1.27165779e-01, -3.12951170e-02,  3.80906761e-02, -4.91855852e-02,\n",
      "        3.89376320e-02, -7.87871927e-02, -4.17702422e-02,  2.09541031e-04,\n",
      "       -6.82846680e-02, -2.28745211e-02, -1.43783703e-01,  1.05826341e-01,\n",
      "       -1.63713340e-02, -8.22098702e-02,  4.31271493e-02, -8.48309770e-02,\n",
      "        4.12067920e-02,  4.48511168e-02,  1.46767944e-02,  1.72731966e-01,\n",
      "       -2.43684817e-02,  3.42418440e-02,  1.88916400e-02, -1.03563682e-32,\n",
      "       -2.53345966e-02, -5.79840280e-02,  1.04456164e-01, -7.00707957e-02,\n",
      "        1.24972999e-01,  1.20758340e-02,  7.43365511e-02,  5.10050245e-02,\n",
      "        7.01797977e-02,  1.39837516e-02, -5.01040295e-02, -6.24146089e-02,\n",
      "       -2.83001475e-02, -3.18315513e-02, -5.21289883e-03,  2.89186109e-02,\n",
      "       -1.60801243e-02, -1.44673679e-02, -6.33246452e-02,  4.53769751e-02,\n",
      "        5.58044901e-03, -5.27324119e-05,  2.67263968e-02,  5.81662878e-02,\n",
      "       -1.50718284e-03,  8.92009810e-02, -3.79671156e-02,  1.78012587e-02,\n",
      "        7.90885612e-02,  3.17721628e-02,  1.84856504e-02,  3.67595665e-02,\n",
      "       -8.24659392e-02, -3.28983217e-02, -2.82460172e-02, -1.31561412e-02,\n",
      "       -7.07228929e-02,  3.27033438e-02,  2.34822165e-02,  1.75265409e-02,\n",
      "       -2.43035494e-04,  7.61630461e-02, -1.24191083e-02, -5.16392887e-02,\n",
      "       -4.05038483e-02, -1.48714855e-02,  4.44570370e-02,  1.83835719e-02,\n",
      "       -1.97970718e-02, -2.55505498e-02, -5.50550781e-02,  6.19681254e-02,\n",
      "        1.80884078e-02,  4.93461676e-02, -1.04276434e-04, -7.34485611e-02,\n",
      "       -3.54518816e-02, -3.69288474e-02,  1.04069235e-02, -7.11702881e-03,\n",
      "        5.85639626e-02, -3.16281021e-02,  3.05113960e-02,  2.20253058e-02,\n",
      "       -2.76904851e-02,  4.88212779e-02, -8.35429057e-02, -6.65509626e-02,\n",
      "        1.19750708e-01, -2.38587637e-03,  2.02257112e-02,  1.59490965e-02,\n",
      "        6.78055212e-02,  2.42517292e-02, -5.14470600e-02,  3.63771953e-02,\n",
      "       -2.99972482e-02, -7.49264732e-02, -1.18242996e-02, -7.89763927e-02,\n",
      "        2.29492150e-02,  3.76609825e-02,  1.45986537e-02, -3.04210894e-02,\n",
      "       -3.78155336e-02, -4.53139022e-02, -9.82891172e-02, -7.32063223e-03,\n",
      "       -1.86485462e-02,  6.75387606e-02, -5.36289513e-02, -4.49206047e-02,\n",
      "        2.61001312e-03,  1.52338054e-02, -3.78234982e-02,  5.70894407e-33,\n",
      "        9.08530131e-02,  7.85488915e-03, -5.64961359e-02, -5.58536127e-02,\n",
      "        2.68970411e-02, -4.99923676e-02, -2.22236849e-02, -3.54944915e-02,\n",
      "       -8.86635408e-02,  1.34043768e-02, -5.07881083e-02, -5.57671487e-03,\n",
      "        2.80572437e-02, -4.25009942e-03,  9.54071507e-02,  3.10445428e-02,\n",
      "        2.38969717e-02,  5.55346683e-02, -1.82013810e-02,  1.28358742e-02,\n",
      "        7.21357316e-02,  5.28344698e-02,  6.22530393e-02,  1.70283895e-02,\n",
      "        1.02514373e-02, -5.65237701e-02,  5.94472587e-02,  1.08019561e-02,\n",
      "       -2.04669293e-02,  1.30245984e-02, -7.49400407e-02, -3.65656763e-02,\n",
      "        6.13859743e-02,  5.90483472e-02, -8.05412419e-03, -2.58289892e-02,\n",
      "       -3.15161571e-02, -9.29064900e-02,  8.74225982e-03,  6.06963784e-03,\n",
      "        4.08966504e-02,  1.23126777e-02,  4.67570424e-02,  7.43555501e-02,\n",
      "        4.62947153e-02, -4.82153744e-02, -8.28349665e-02,  9.98858828e-03,\n",
      "       -1.88214183e-02, -4.69335280e-02, -3.18621448e-03, -9.87408832e-02,\n",
      "        9.54793170e-02, -5.24985977e-02,  5.48410490e-02,  8.79623294e-02,\n",
      "       -3.72548923e-02, -4.28454019e-02,  2.71155164e-02,  3.19985002e-02,\n",
      "       -3.15151066e-02,  1.33361682e-01,  2.34344639e-02,  3.56656313e-02,\n",
      "        4.04392928e-02,  1.10709153e-01, -6.29193410e-02,  4.98631075e-02,\n",
      "        1.59943290e-02,  3.33532356e-02, -7.13473186e-02, -5.71079291e-02,\n",
      "       -2.38733776e-02,  7.96174109e-02,  6.14643432e-02,  2.46907640e-02,\n",
      "       -3.76653369e-03,  7.00659230e-02, -1.73017755e-02, -1.00807175e-01,\n",
      "       -5.37035279e-02, -6.40752986e-02,  4.58276309e-02, -8.59290361e-02,\n",
      "       -2.47677602e-03, -2.47238148e-02,  2.08030343e-02, -5.46366647e-02,\n",
      "       -6.38827309e-02, -2.15923972e-02, -4.17891555e-02, -2.28613708e-02,\n",
      "       -7.45589808e-02,  1.19280899e-02,  2.66051199e-02, -1.84731999e-08,\n",
      "       -4.78009431e-04, -5.81023023e-02, -2.29187533e-02, -5.38815856e-02,\n",
      "        3.14529426e-02, -8.19447711e-02,  1.59363747e-01, -2.54773279e-03,\n",
      "       -6.66592941e-02, -8.64046216e-02, -8.36314261e-03,  7.00603202e-02,\n",
      "        9.32323635e-02, -2.89818589e-02,  1.97238717e-02,  3.25710885e-02,\n",
      "       -4.79388162e-02,  1.91430654e-02, -1.45873167e-02,  4.97973971e-02,\n",
      "        5.04771434e-02, -3.38296331e-02,  5.53078763e-02, -8.33945174e-04,\n",
      "        5.36136143e-02, -9.70690395e-04, -2.87807006e-02,  5.20652533e-02,\n",
      "       -2.00869553e-02,  7.92800412e-02,  2.79875621e-02, -1.34941461e-02,\n",
      "        5.26853185e-03,  4.41365913e-02,  6.69401735e-02,  3.22599150e-02,\n",
      "       -3.69083397e-02, -3.41813304e-02, -6.09918982e-02, -2.66691037e-02,\n",
      "       -7.39278868e-02, -1.52297858e-02,  3.16975228e-02, -8.13229475e-03,\n",
      "        9.59088504e-02,  3.03144660e-02, -9.44986343e-02,  1.05578946e-02,\n",
      "        1.22779151e-02,  1.70453498e-03, -5.36285825e-02, -4.52814661e-02,\n",
      "        4.94368076e-02,  3.62515301e-02, -7.96795338e-02,  3.36945094e-02,\n",
      "        7.50833079e-02,  4.02822830e-02, -5.55942878e-02,  3.86159457e-02,\n",
      "        6.38851747e-02,  5.18730171e-02,  2.42348388e-02,  1.05276750e-02],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve sentence embeddings\n",
    "\n",
    "models = [\"Alibaba-NLP_gte-large-en-v1.5\",\n",
    "          \"intfloat_multilingual-e5-large\",\n",
    "          \"sentence-transformers_all-mpnet-base-v2\",\n",
    "          \"sentence-transformers_all-MiniLM-L6-v2\"]\n",
    "\n",
    "file_paths = [f\"../data/{model}.pt\" for model in models]\n",
    "\n",
    "# Dictionary to store the data\n",
    "embeddings = {}\n",
    "\n",
    "# Load the data\n",
    "for model in models:\n",
    "    try:\n",
    "        file_path = f\"../data/{model}.pt\"\n",
    "        data = torch.load(file_path, map_location=\"cpu\")  # Load on CPU to avoid GPU issues\n",
    "        print(f\"Data loaded successfully from {file_path}!\")\n",
    "\n",
    "        # Store the data in the dictionary\n",
    "        embeddings[model] = data\n",
    "\n",
    "        # Print the type of the loaded object\n",
    "        print(\"Loaded data type:\", type(data))\n",
    "        print(\"List length:\", len(data))\n",
    "        print(\"First item:\", data[0])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file {file_path}: {e}\")\n",
    "\n",
    "# Now embeddings dictionary contains data from all the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of X embeddings per model: {'Alibaba-NLP_gte-large-en-v1.5': 2784, 'intfloat_multilingual-e5-large': 2784, 'sentence-transformers_all-mpnet-base-v2': 2784, 'sentence-transformers_all-MiniLM-L6-v2': 2784}\n",
      "Number of y embeddings per model: {'Alibaba-NLP_gte-large-en-v1.5': 2784, 'intfloat_multilingual-e5-large': 2784, 'sentence-transformers_all-mpnet-base-v2': 2784, 'sentence-transformers_all-MiniLM-L6-v2': 2784}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve embeddings for X and y\n",
    "X_embeddings = {model: [] for model in models}\n",
    "y_embeddings = {model: [] for model in models}\n",
    "\n",
    "for model in models:\n",
    "    for data_point in embeddings[model]:\n",
    "        if data_point['sentence'] in X_df['table_sentence'].values:\n",
    "            X_embeddings[model].append(data_point['embedding'])\n",
    "        if data_point['sentence'] in y_df['chair_sentence'].values:\n",
    "            y_embeddings[model].append(data_point['embedding'])\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_embeddings = {model: np.array(embeddings) for model, embeddings in X_embeddings.items()}\n",
    "y_embeddings = {model: np.array(embeddings) for model, embeddings in y_embeddings.items()}\n",
    "\n",
    "print(\"Number of X embeddings per model:\", {model: len(embeddings) for model, embeddings in X_embeddings.items()})\n",
    "print(\"Number of y embeddings per model:\", {model: len(embeddings) for model, embeddings in y_embeddings.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for linear_model_Alibaba-NLP_gte-large-en-v1.5: 0.00\n",
      "MSE for linear_model_intfloat_multilingual-e5-large: 0.00\n",
      "MSE for linear_model_sentence-transformers_all-mpnet-base-v2: 0.00\n",
      "MSE for linear_model_sentence-transformers_all-MiniLM-L6-v2: 0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def train_linear_mapping_on_embeddings(X_embeddings, y_embeddings, results_dict, models_dict, model_name):\n",
    "\n",
    "    X = X_embeddings[model_name]\n",
    "    y = y_embeddings[model_name]\n",
    "    # print(X.shape, y.shape)\n",
    "\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, y)\n",
    "    model_name = f\"linear_model_{model_name}\"\n",
    "    models_dict[model_name] = linear_model\n",
    "\n",
    "    y_pred = linear_model.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    results_dict[model_name] = mse\n",
    "    print(f\"MSE for {model_name}: {mse:.2f}\")\n",
    "\n",
    "# Example usage\n",
    "mapping_results = {}\n",
    "mapping_models = {}\n",
    "\n",
    "for model_name in models:\n",
    "    train_linear_mapping_on_embeddings(X_embeddings, y_embeddings, mapping_results, mapping_models, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More complex transformation\n",
    "\n",
    "Now let's try to go from sentences \"[subject] [relation] [object]\" to \"[object] [opposite relation] [table]\".\n",
    "This will decrease the number of dimensions, as it's a many-to-one mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'category': 'vertical', 'opposite': 'above', 'position': 1}\n",
      "0 The table is above the chair. The chair is below the table.\n",
      "100 The table is near the bed. The bed is distant from the table.\n",
      "200 The table is perpendicular to the cup. The cup is parallel to the table.\n",
      "300 The table is within the car. The car is beyond the table.\n",
      "400 The table is oriented toward the clock. The clock is oriented away from the table.\n",
      "500 The table is ahead of the television. The television is at the back of the table.\n",
      "600 The table is connected to the backpack. The backpack is disconnected from the table.\n",
      "700 The table is elevated above the key. The key is dropped below the table.\n",
      "800 The table is on the towel. The towel is off the table.\n",
      "900 The table is over the mirror. The mirror is under the table.\n",
      "1000 The table is next to the camera. The camera is away from the table.\n",
      "1100 The table is equidistant from the umbrella. The umbrella is closer to the table.\n",
      "1200 The table is enclosed in the toy. The toy is excluded from the table.\n",
      "1300 The table is diagonally above-left the plate. The plate is diagonally below-right the table.\n",
      "1400 The table is before the bag. The bag is after the table.\n",
      "1500 The chair is facing the sofa. The sofa is back to the table.\n",
      "1600 The chair is to the left of the cup. The cup is to the right of the table.\n",
      "1700 The chair is attached to the window. The window is detached from the table.\n",
      "1800 The chair is on top of the clock. The clock is beneath the table.\n",
      "1900 The chair is adjacent to the phone. The phone is opposite from the table.\n",
      "2000 The chair is at 45 degrees to the candle. The candle is at 225 degrees to the table.\n",
      "2100 The chair is close to the notebook. The notebook is far from the table.\n",
      "2200 The chair is diagonally above-right the shoe. The shoe is diagonally below-left the table.\n",
      "2300 The chair is inside the plant. The plant is outside the table.\n",
      "2400 The chair is pointing toward the fan. The fan is pointing away from the table.\n",
      "2500 The chair is in front of the umbrella. The umbrella is behind the table.\n",
      "2600 The chair is stuck to the ball. The ball is separated from the table.\n",
      "2700 The chair is higher than the plate. The plate is lower than the table.\n",
      "2800 The chair is beside the charger. The charger is apart from the table.\n",
      "2900 The lamp is above the sofa. The sofa is below the table.\n",
      "3000 The lamp is near the book. The book is distant from the table.\n",
      "3100 The lamp is perpendicular to the door. The door is parallel to the table.\n",
      "3200 The lamp is within the rock. The rock is beyond the table.\n",
      "3300 The lamp is oriented toward the laptop. The laptop is oriented away from the table.\n",
      "3400 The lamp is ahead of the candle. The candle is at the back of the table.\n",
      "3500 The lamp is connected to the pen. The pen is disconnected from the table.\n",
      "3600 The lamp is elevated above the shoe. The shoe is dropped below the table.\n",
      "3700 The lamp is on the basket. The basket is off the table.\n",
      "3800 The lamp is over the fan. The fan is under the table.\n",
      "3900 The lamp is next to the brush. The brush is away from the table.\n"
     ]
    }
   ],
   "source": [
    "model = models[0]\n",
    "embedding_info = embeddings[model]\n",
    "#List of {sentence, relation, subject, object, embedding}\n",
    "\n",
    "RELATIONS_JSON_PATH = '../data/relations.json'\n",
    "with open(RELATIONS_JSON_PATH, 'r') as f:\n",
    "    relations = json.load(f)['spatial_relations']\n",
    "def get_relations_lookup(relations):\n",
    "    relations_lookup = {}\n",
    "    for category, category_pairs in relations.items():\n",
    "        for first, second in category_pairs:\n",
    "            relations_lookup[first] = {'category': category, 'opposite': second, 'position': 0}\n",
    "            relations_lookup[second] = {'category': category, 'opposite': first, 'position': 1}\n",
    "    return relations_lookup\n",
    "\n",
    "relations_lookup = get_relations_lookup(relations)\n",
    "print(relations_lookup['below'])\n",
    "\n",
    "embedding_dict = {info['sentence']: info['embedding'] for info in embedding_info}\n",
    "\n",
    "X_sentences = [info['sentence'] for info in embedding_info]\n",
    "X = []\n",
    "y_info = embedding_info.copy()\n",
    "y = []\n",
    "count = 0\n",
    "for info in y_info:\n",
    "    sentence = info['sentence']\n",
    "    ob = info['object']\n",
    "    rel = info['relation']\n",
    "    rel_op = relations_lookup[rel]['opposite']\n",
    "    new_sentence = f\"The {ob} is {rel_op} the table.\"\n",
    "    if count % 100 == 0 and count < 4000:\n",
    "        print(count,info['sentence'],new_sentence)\n",
    "    if new_sentence in embedding_dict:\n",
    "        X.append(embedding_dict[sentence])\n",
    "        y.append(embedding_dict[new_sentence])\n",
    "    count += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(139258, 1024) (139258, 1024)\n",
      "MSE for linear_model_Alibaba-NLP_gte-large-en-v1.5: 0.06\n"
     ]
    }
   ],
   "source": [
    "X_embeddings = np.array(X)\n",
    "y_embeddings = np.array(y)\n",
    "print(X_embeddings.shape, y_embeddings.shape)\n",
    "\n",
    "results_dict = {}\n",
    "models_dict = {}\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X, y)\n",
    "model_name = f\"linear_model_{model_name}\"\n",
    "models_dict[model_name] = linear_model\n",
    "\n",
    "y_pred = linear_model.predict(X)\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "results_dict[model_name] = mse\n",
    "print(f\"MSE for {model_name}: {mse:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatgeo-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
