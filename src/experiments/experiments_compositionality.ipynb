{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compositionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Step 1: Get all the sentences\n",
    "2. Step 2: Get the probes \n",
    "3. Step 3: Test for compositionality ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MODELS = [\n",
    "    \"Alibaba-NLP/gte-large-en-v1.5\",\n",
    "    \"intfloat/multilingual-e5-large\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'https://huggingface.co/datasets/matthieunlp/spatial_geometry/resolve/main/src/data/sentence-embeddings'\n",
    "RELATIONS_JSON_PATH = '../data/relations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RELATIONS_JSON_PATH, 'r') as f:\n",
    "    relations = json.load(f)['spatial_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_lookup(relations):\n",
    "    relations_lookup = {}\n",
    "    for category, category_pairs in relations.items():\n",
    "        for first, second in category_pairs:\n",
    "            relations_lookup[first] = {'category': category, 'opposite': second, 'position': 0}\n",
    "            relations_lookup[second] = {'category': category, 'opposite': first, 'position': 1}\n",
    "    return relations_lookup\n",
    "\n",
    "relations_lookup = get_relations_lookup(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_for_model(model_name, datapoint='relation'):\n",
    "    import requests\n",
    "    from io import BytesIO\n",
    "\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    url = f'{DATA_PATH}/{model_name.replace(\"/\", \"_\")}.pt'\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    raw_data = torch.load(BytesIO(response.content), weights_only=False)\n",
    "    \n",
    "    for data_point in raw_data:\n",
    "        embeddings.append(data_point['embedding'])\n",
    "        labels.append(data_point[datapoint])\n",
    "    return np.array(embeddings), np.array(labels).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probes for all relations\n",
    "\n",
    "We expect that we will find linear relations, but we also have to isolate the syntaxic elements. \n",
    "\n",
    "We train a couple series of probes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multitask_probe_for_datapoint(results_dict, models_dict, encoder):\n",
    "    for model_name in MODELS:\n",
    "        print(f\"Training multitask probe for {model_name} on all datapoints...\")\n",
    "        X, y_relation = load_embeddings_for_model(model_name, datapoint='relation')\n",
    "        X, y_subject = load_embeddings_for_model(model_name, datapoint='subject')\n",
    "        X, y_object = load_embeddings_for_model(model_name, datapoint='object')\n",
    "\n",
    "        # One-hot encode all labels together\n",
    "        y_combined = np.column_stack([y_relation, y_subject, y_object])  # Stack labels side by side\n",
    "        y_encoded = encoder.fit_transform(y_combined).todense()\n",
    "        \n",
    "        y_encoded = encoder.fit_transform(y).todense()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        # Train probe\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(), \n",
    "                            early_stopping=True, \n",
    "                            activation='identity')\n",
    "        clf.fit(X_train, y_train)\n",
    "        models_dict[model_name] = clf\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_dict[model_name] = accuracy\n",
    "        print(f\"Accuracy for {model_name}: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probe for Alibaba-NLP/gte-large-en-v1.5 on relation...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 1.00\n",
      "Training probe for intfloat/multilingual-e5-large on relation...\n",
      "Accuracy for intfloat/multilingual-e5-large: 1.00\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2 on relation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 0.99\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2 on relation...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 1.00\n",
      "Training probe for Alibaba-NLP/gte-large-en-v1.5 on subject...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 1.00\n",
      "Training probe for intfloat/multilingual-e5-large on subject...\n",
      "Accuracy for intfloat/multilingual-e5-large: 0.99\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2 on subject...\n",
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 1.00\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2 on subject...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 1.00\n",
      "Training probe for Alibaba-NLP/gte-large-en-v1.5 on object...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 0.99\n",
      "Training probe for intfloat/multilingual-e5-large on object...\n",
      "Accuracy for intfloat/multilingual-e5-large: 0.99\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2 on object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 0.98\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2 on object...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 0.97\n",
      "Training multitask probe for Alibaba-NLP/gte-large-en-v1.5 on all datapoints...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: 0.99\n",
      "Training multitask probe for intfloat/multilingual-e5-large on all datapoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for intfloat/multilingual-e5-large: 0.99\n",
      "Training multitask probe for sentence-transformers/all-mpnet-base-v2 on all datapoints...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for sentence-transformers/all-mpnet-base-v2: 0.98\n",
      "Training multitask probe for sentence-transformers/all-MiniLM-L6-v2 on all datapoints...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/matthieu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def train_probe_for_datapoint(datapoint, results_dict, models_dict, encoder):\n",
    "    for model_name in MODELS:\n",
    "        print(f\"Training probe for {model_name} on {datapoint}...\")\n",
    "        X, y = load_embeddings_for_model(model_name, datapoint=datapoint)\n",
    "        y_encoded = encoder.fit_transform(y).todense()\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
    "\n",
    "        y_train = np.asarray(y_train)\n",
    "        y_test = np.asarray(y_test)\n",
    "\n",
    "        # Train probe\n",
    "        clf = MLPClassifier(hidden_layer_sizes=(), early_stopping=True, activation='identity')\n",
    "        clf.fit(X_train, y_train)\n",
    "        models_dict[model_name] = clf\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results_dict[model_name] = accuracy\n",
    "        print(f\"Accuracy for {model_name}: {accuracy:.2f}\")\n",
    "\n",
    "\n",
    "results = {}\n",
    "models = {}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "subject_results = {}\n",
    "subject_models = {}\n",
    "subject_one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "object_results = {}\n",
    "object_models = {}\n",
    "object_one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "multitask_results = {}\n",
    "multitask_models = {}\n",
    "multitask_one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "train_probe_for_datapoint('relation', results, models, one_hot_encoder)\n",
    "train_probe_for_datapoint('subject', subject_results, subject_models, subject_one_hot_encoder)\n",
    "train_probe_for_datapoint('object', object_results, object_models, object_one_hot_encoder)\n",
    "train_multitask_probe_for_datapoint(multitask_results, multitask_models, multitask_one_hot_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "class PickleSaver:\n",
    "    def __init__(self, data, filename):\n",
    "        self.data = data\n",
    "        self.filename = filename\n",
    "\n",
    "    def save(self):\n",
    "        with open(self.filename, 'wb') as f:\n",
    "            pickle.dump(self.data, f)\n",
    "\n",
    "# Create instances of PickleSaver for each data object\n",
    "pickle_savers = [\n",
    "    PickleSaver(results, 'results.pkl'),\n",
    "    PickleSaver(models, 'models.pkl'),\n",
    "    PickleSaver(one_hot_encoder, 'one_hot_encoder.pkl'),\n",
    "    PickleSaver(subject_results, 'subject_results.pkl'),\n",
    "    PickleSaver(subject_models, 'subject_models.pkl'),\n",
    "    PickleSaver(subject_one_hot_encoder, 'subject_one_hot_encoder.pkl'),\n",
    "    PickleSaver(object_results, 'object_results.pkl'),\n",
    "    PickleSaver(object_models, 'object_models.pkl'),\n",
    "    PickleSaver(object_one_hot_encoder, 'object_one_hot_encoder.pkl'),\n",
    "    PickleSaver(multitask_results, 'multitask_results.pkl'),\n",
    "    PickleSaver(multitask_models, 'multitask_models.pkl'),\n",
    "    PickleSaver(multitask_one_hot_encoder, 'multitask_one_hot_encoder.pkl')\n",
    "]\n",
    "\n",
    "# Save all data using the PickleSaver instances\n",
    "for saver in pickle_savers:\n",
    "    saver.save()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding all the elements\n",
    "\n",
    "We then build a dictionnary with the representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation between subject and object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject model: Alibaba-NLP/gte-large-en-v1.5\n",
      "Processing subject model: intfloat/multilingual-e5-large\n",
      "Processing subject model: sentence-transformers/all-mpnet-base-v2\n",
      "Processing subject model: sentence-transformers/all-MiniLM-L6-v2\n",
      "Processing object model: Alibaba-NLP/gte-large-en-v1.5\n",
      "Processing object model: intfloat/multilingual-e5-large\n",
      "Processing object model: sentence-transformers/all-mpnet-base-v2\n",
      "Processing object model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "subject_class_representations = {}\n",
    "for model_name, clf in subject_models.items():\n",
    "    print(f\"Processing subject model: {model_name}\")\n",
    "    weights = clf.coefs_[0]\n",
    "    class_names = subject_one_hot_encoder.get_feature_names_out()\n",
    "    subject_class_representations[model_name] = {\n",
    "        class_name.replace('x0_', ''): weights[:, i]\n",
    "        for i, class_name in enumerate(class_names)\n",
    "    }\n",
    "\n",
    "# For object models\n",
    "object_class_representations = {}\n",
    "for model_name, clf in object_models.items():\n",
    "    print(f\"Processing object model: {model_name}\")\n",
    "    weights = clf.coefs_[0]\n",
    "    class_names = object_one_hot_encoder.get_feature_names_out()\n",
    "    object_class_representations[model_name] = {\n",
    "        class_name.replace('x0_', ''): weights[:, i]\n",
    "        for i, class_name in enumerate(class_names)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                model_name  \\\n",
      "0            Alibaba-NLP/gte-large-en-v1.5   \n",
      "1           intfloat/multilingual-e5-large   \n",
      "2  sentence-transformers/all-mpnet-base-v2   \n",
      "3   sentence-transformers/all-MiniLM-L6-v2   \n",
      "\n",
      "                                   subject_embedding  \\\n",
      "0  {'backpack': [0.45930824, 0.13927732, 0.052427...   \n",
      "1  {'backpack': [1.5536985, -1.935699, -2.3292258...   \n",
      "2  {'backpack': [0.15356827, 0.8909149, 2.0928144...   \n",
      "3  {'backpack': [7.621316, -2.8898807, 1.0278848,...   \n",
      "\n",
      "                                    object_embedding  \n",
      "0  {'backpack': [-0.4304129, -0.319799, -0.475969...  \n",
      "1  {'backpack': [-0.9528372, -0.9325819, -0.30154...  \n",
      "2  {'backpack': [-0.26464918, 1.5674798, -1.01602...  \n",
      "3  {'backpack': [-14.387648, 0.7471546, 2.85581, ...  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected Tensor as element 0 in argument 0, but got dict",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m     subject_embeddings\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubject_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     20\u001b[0m     object_embeddings\u001b[38;5;241m.\u001b[39mappend(item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 23\u001b[0m subject_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     24\u001b[0m object_embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(object_embeddings)\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "\u001b[0;31mTypeError\u001b[0m: expected Tensor as element 0 in argument 0, but got dict"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "merged_class_representations = []\n",
    "\n",
    "for model_name in subject_class_representations.keys():\n",
    "    if model_name in object_class_representations:\n",
    "        merged_class_representations.append({\n",
    "            \"model_name\": model_name,\n",
    "            \"subject_embedding\": subject_class_representations[model_name],\n",
    "            \"object_embedding\": object_class_representations[model_name]\n",
    "        })\n",
    "\n",
    "merged_class_representations_df = pd.DataFrame(merged_class_representations)\n",
    "print(merged_class_representations_df)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model: Alibaba-NLP/gte-large-en-v1.5\n",
      "\n",
      "Class: backpack\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bag\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: ball\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: basket\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bed\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bicycle\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: book\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bottle\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: box\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: brush\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: camera\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: candle\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: car\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: chair\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: charger\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: clock\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: coat\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: cup\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: door\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: fan\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: fence\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: fork\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: hat\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: key\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: knife\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: lamp\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: laptop\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: mirror\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: notebook\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: pen\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: phone\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: picture frame\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: pillow\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: plant\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: plate\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: remote\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: rock\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: shelf\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: shoe\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: sofa\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: speaker\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: statue\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: sunglasses\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: table\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: television\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: towel\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: toy\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: tree\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: umbrella\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: window\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Model: intfloat/multilingual-e5-large\n",
      "\n",
      "Class: backpack\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bag\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: ball\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: basket\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bed\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bicycle\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: book\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: bottle\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: box\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: brush\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: camera\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: candle\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: car\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: chair\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: charger\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: clock\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: coat\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: cup\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: door\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: fan\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: fence\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: fork\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: hat\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: key\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: knife\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: lamp\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: laptop\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: mirror\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: notebook\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: pen\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: phone\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: picture frame\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: pillow\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: plant\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: plate\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: remote\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: rock\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: shelf\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: shoe\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: sofa\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: speaker\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: statue\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: sunglasses\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: table\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: television\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: towel\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: toy\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: tree\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: umbrella\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Class: window\n",
      "Subject embeddings shape: (1, 1024)\n",
      "Object embeddings shape: (1, 1024)\n",
      "\n",
      "Model: sentence-transformers/all-mpnet-base-v2\n",
      "\n",
      "Class: backpack\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: bag\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: ball\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: basket\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: bed\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: bicycle\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: book\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: bottle\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: box\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: brush\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: camera\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: candle\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: car\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: chair\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: charger\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: clock\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: coat\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: cup\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: door\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: fan\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: fence\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: fork\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: hat\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: key\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: knife\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: lamp\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: laptop\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: mirror\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: notebook\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: pen\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: phone\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: picture frame\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: pillow\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: plant\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: plate\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: remote\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: rock\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: shelf\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: shoe\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: sofa\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: speaker\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: statue\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: sunglasses\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: table\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: television\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: towel\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: toy\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: tree\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: umbrella\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Class: window\n",
      "Subject embeddings shape: (1, 768)\n",
      "Object embeddings shape: (1, 768)\n",
      "\n",
      "Model: sentence-transformers/all-MiniLM-L6-v2\n",
      "\n",
      "Class: backpack\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: bag\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: ball\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: basket\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: bed\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: bicycle\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: book\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: bottle\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: box\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: brush\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: camera\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: candle\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: car\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: chair\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: charger\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: clock\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: coat\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: cup\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: door\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: fan\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: fence\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: fork\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: hat\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: key\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: knife\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: lamp\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: laptop\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: mirror\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: notebook\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: pen\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: phone\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: picture frame\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: pillow\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: plant\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: plate\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: remote\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: rock\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: shelf\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: shoe\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: sofa\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: speaker\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: statue\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: sunglasses\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: table\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: television\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: towel\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: toy\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: tree\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: umbrella\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n",
      "\n",
      "Class: window\n",
      "Subject embeddings shape: (1, 384)\n",
      "Object embeddings shape: (1, 384)\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries to store embeddings for each model and class\n",
    "subject_embeddings_by_model = {}\n",
    "object_embeddings_by_model = {}\n",
    "\n",
    "# Group by model name and class\n",
    "for item in merged_class_representations:\n",
    "    model_name = item[\"model_name\"]\n",
    "    \n",
    "    # Initialize dicts for new models\n",
    "    if model_name not in subject_embeddings_by_model:\n",
    "        subject_embeddings_by_model[model_name] = {}\n",
    "        object_embeddings_by_model[model_name] = {}\n",
    "    \n",
    "    # Store all class representations\n",
    "    for class_name, embedding in item[\"subject_embedding\"].items():\n",
    "        if class_name not in subject_embeddings_by_model[model_name]:\n",
    "            subject_embeddings_by_model[model_name][class_name] = []\n",
    "        subject_embeddings_by_model[model_name][class_name].append(torch.tensor(embedding))\n",
    "    \n",
    "    for class_name, embedding in item[\"object_embedding\"].items():\n",
    "        if class_name not in object_embeddings_by_model[model_name]:\n",
    "            object_embeddings_by_model[model_name][class_name] = []\n",
    "        object_embeddings_by_model[model_name][class_name].append(torch.tensor(embedding))\n",
    "\n",
    "# Stack tensors for each model and class\n",
    "subject_stacked = {\n",
    "    model_name: {\n",
    "        class_name: torch.stack(tensors).numpy()\n",
    "        for class_name, tensors in class_dict.items()\n",
    "    }\n",
    "    for model_name, class_dict in subject_embeddings_by_model.items()\n",
    "}\n",
    "\n",
    "object_stacked = {\n",
    "    model_name: {\n",
    "        class_name: torch.stack(tensors).numpy()\n",
    "        for class_name, tensors in class_dict.items()\n",
    "    }\n",
    "    for model_name, class_dict in object_embeddings_by_model.items()\n",
    "}\n",
    "\n",
    "# Now you can access embeddings for each model and class:\n",
    "for model_name in subject_stacked:\n",
    "    print(f\"\\nModel: {model_name}\")\n",
    "    for class_name in subject_stacked[model_name]:\n",
    "        print(f\"\\nClass: {class_name}\")\n",
    "        print(f\"Subject embeddings shape: {subject_stacked[model_name][class_name].shape}\")\n",
    "        print(f\"Object embeddings shape: {object_stacked[model_name][class_name].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicted object embeddings\n",
      "Mean Squared Error for linear: 0.000000\n",
      "\n",
      "Predicted object embeddings with regularization\n",
      "Mean Squared Error for ridge: 0.000017\n",
      "\n",
      "Predicted object embeddings\n",
      "Mean Squared Error for linear: 0.000000\n",
      "\n",
      "Predicted object embeddings with regularization\n",
      "Mean Squared Error for ridge: 0.000000\n",
      "\n",
      "Predicted object embeddings\n",
      "Mean Squared Error for linear: 0.000000\n",
      "\n",
      "Predicted object embeddings with regularization\n",
      "Mean Squared Error for ridge: 0.000001\n",
      "\n",
      "Predicted object embeddings\n",
      "Mean Squared Error for linear: 0.000000\n",
      "\n",
      "Predicted object embeddings with regularization\n",
      "Mean Squared Error for ridge: 0.000001\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class EmbeddingModelTrainer:\n",
    "    def __init__(self, subject_embeddings, object_embeddings):\n",
    "        self.X = np.vstack([arr.squeeze() for arr in subject_embeddings.values()])\n",
    "        self.y = np.vstack([arr.squeeze() for arr in object_embeddings.values()])\n",
    "        self.models = {}\n",
    "\n",
    "    def train_linear_model(self):\n",
    "        self.models['linear'] = LinearRegression()\n",
    "        self.models['linear'].fit(self.X, self.y)\n",
    "        self.models['linear_inverse'] = LinearRegression()\n",
    "        self.models['linear_inverse'].fit(self.y, self.X)\n",
    "\n",
    "    def train_ridge_model(self, alpha=1.0):\n",
    "        self.models['ridge'] = Ridge(alpha=alpha, fit_intercept=True, solver='svd')\n",
    "        self.models['ridge'].fit(self.X, self.y)\n",
    "        self.models['ridge_inverse'] = Ridge(alpha=alpha, fit_intercept=True, solver='svd')\n",
    "        self.models['ridge_inverse'].fit(self.y, self.X)\n",
    "\n",
    "    def evaluate_model(self, model_name, embeddings, true_embeddings):\n",
    "        predictions = self.models[model_name].predict(embeddings)\n",
    "        mse = mean_squared_error(true_embeddings, predictions)\n",
    "        mae = mean_absolute_error(true_embeddings, predictions)\n",
    "        r2 = r2_score(true_embeddings, predictions)\n",
    "        return predictions, mse, mae, r2\n",
    "\n",
    "    def print_evaluation(self, model_name, X_test, y_true, description):\n",
    "        # Convert test data to proper format\n",
    "        X_test = np.vstack([arr.squeeze() for arr in X_test.values()])\n",
    "        y_true = np.vstack([arr.squeeze() for arr in y_true.values()])\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = self.models[model_name].predict(X_test)\n",
    "        \n",
    "        # Calculate MSE\n",
    "        mse = mean_squared_error(y_true, y_pred)\n",
    "        print(f\"\\n{description}\")\n",
    "        print(f\"Mean Squared Error for {model_name}: {mse:.6f}\")\n",
    "\n",
    "# Usage\n",
    "for model_name in subject_stacked:\n",
    "    subject_embeddings = subject_stacked[model_name]\n",
    "    object_embeddings = object_stacked[model_name]\n",
    "    trainer = EmbeddingModelTrainer(subject_embeddings, object_embeddings)\n",
    "    trainer.train_linear_model()\n",
    "    trainer.train_ridge_model()\n",
    "\n",
    "    trainer.print_evaluation('linear', subject_embeddings, object_embeddings, \"Predicted object embeddings\")\n",
    "    trainer.print_evaluation('ridge', subject_embeddings, object_embeddings, \"Predicted object embeddings with regularization\")\n",
    "    # trainer.print_evaluation('linear_inverse', object_embeddings, subject_embeddings, \"Predicted subject embeddings\")\n",
    "    # trainer.print_evaluation('ridge_inverse', trainer.models['ridge'].predict(subject_embeddings), subject_embeddings, \"Predicted subject embeddings with regularization inverse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'backpack': array([ 0.45930824,  0.13927732,  0.05242767, ...,  0.04325312,\n",
       "        -0.23257335,  0.133842  ], dtype=float32),\n",
       " 'bag': array([ 0.24440594, -0.17168754, -0.88721865, ..., -0.5350134 ,\n",
       "        -0.15706661, -0.334713  ], dtype=float32),\n",
       " 'ball': array([ 0.23578249,  0.13245244, -0.31964183, ...,  0.08768918,\n",
       "        -0.08186665,  0.19385338], dtype=float32),\n",
       " 'basket': array([ 0.33961737, -0.18598752, -0.02805528, ..., -0.15965174,\n",
       "         0.12199956, -0.24671899], dtype=float32),\n",
       " 'bed': array([ 0.1752361 , -0.23391986,  0.02540315, ..., -0.32959452,\n",
       "        -0.1558452 ,  0.13773447], dtype=float32),\n",
       " 'bicycle': array([-0.5912732 ,  0.18265815, -0.13700363, ..., -0.2944202 ,\n",
       "         0.20219561,  0.10965832], dtype=float32),\n",
       " 'book': array([ 0.6345695 ,  0.14126243, -0.0973493 , ..., -0.57434565,\n",
       "         0.11965234,  0.13884461], dtype=float32),\n",
       " 'bottle': array([ 0.5292081 ,  0.26253563,  0.1514274 , ...,  0.09160279,\n",
       "         0.02351419, -0.04712278], dtype=float32),\n",
       " 'box': array([-0.1256794 , -0.28860557, -0.24355212, ..., -0.16294351,\n",
       "        -0.13784465,  0.34726465], dtype=float32),\n",
       " 'brush': array([-0.25805396, -0.23555864,  0.07636455, ..., -0.29850253,\n",
       "         0.6784567 , -0.14612879], dtype=float32),\n",
       " 'camera': array([0.05414282, 0.2559862 , 0.3063216 , ..., 0.22385031, 0.08346845,\n",
       "        0.6258474 ], dtype=float32),\n",
       " 'candle': array([ 0.56760806, -0.15032403, -0.29731244, ..., -0.09973054,\n",
       "         0.6374721 , -0.29997385], dtype=float32),\n",
       " 'car': array([ 0.09833407,  0.59784204, -0.36498195, ..., -0.23305164,\n",
       "         0.31417745,  0.36929023], dtype=float32),\n",
       " 'chair': array([ 0.58013254, -0.4154661 , -0.37428063, ..., -0.22629853,\n",
       "         0.3243012 ,  0.2551267 ], dtype=float32),\n",
       " 'charger': array([-0.33048266,  0.5597833 , -0.45525375, ...,  0.02856252,\n",
       "         0.3606237 , -0.08295648], dtype=float32),\n",
       " 'clock': array([ 0.21518901, -0.28364024, -0.20974556, ..., -0.03880373,\n",
       "        -0.09167602,  0.758815  ], dtype=float32),\n",
       " 'coat': array([-0.2360496 ,  0.20138998, -0.49753454, ..., -0.32655582,\n",
       "         0.731289  ,  0.06966165], dtype=float32),\n",
       " 'cup': array([-0.14680898,  0.57140577, -0.2715551 , ...,  0.1598785 ,\n",
       "         0.6883661 ,  0.04851519], dtype=float32),\n",
       " 'door': array([ 0.28475612,  0.05097077,  0.1657211 , ..., -0.1806252 ,\n",
       "        -0.09164425,  0.42352343], dtype=float32),\n",
       " 'fan': array([ 0.7484014 ,  0.03315049, -0.1467394 , ..., -0.1823997 ,\n",
       "        -0.03685901,  0.15477741], dtype=float32),\n",
       " 'fence': array([-0.3390772 ,  0.02768241, -0.43860966, ...,  0.04024689,\n",
       "         0.1339551 ,  0.37729856], dtype=float32),\n",
       " 'fork': array([ 0.08076654, -0.00945523,  0.03875109, ...,  0.31824318,\n",
       "         1.245965  ,  0.46012628], dtype=float32),\n",
       " 'hat': array([0.17478415, 0.18393248, 0.20974329, ..., 0.02798044, 0.7242952 ,\n",
       "        0.10612784], dtype=float32),\n",
       " 'key': array([ 0.06421711, -0.24217787, -0.4539104 , ..., -0.6631401 ,\n",
       "         0.17718717, -0.07600861], dtype=float32),\n",
       " 'knife': array([-0.17079483, -0.42131916,  0.5554988 , ..., -0.12155551,\n",
       "         0.12848169,  0.33922812], dtype=float32),\n",
       " 'lamp': array([ 0.83234155, -0.2454486 ,  0.5316117 , ...,  0.15497005,\n",
       "         0.16561814, -0.51203746], dtype=float32),\n",
       " 'laptop': array([ 0.39118868, -0.07182667, -0.07167424, ...,  0.0041593 ,\n",
       "         0.3103601 ,  0.06622347], dtype=float32),\n",
       " 'mirror': array([ 0.74908584, -0.217591  , -0.34092522, ..., -0.26116776,\n",
       "         0.11339256,  0.25517458], dtype=float32),\n",
       " 'notebook': array([-0.40446028,  0.49854526,  0.06436848, ...,  0.1554675 ,\n",
       "         0.33105174, -0.01811944], dtype=float32),\n",
       " 'pen': array([ 0.510574  , -0.39092925, -0.312547  , ...,  0.2793474 ,\n",
       "         0.7672933 , -0.5704508 ], dtype=float32),\n",
       " 'phone': array([-0.08162365,  0.27097428, -0.1116924 , ...,  0.12294058,\n",
       "         0.2651191 ,  0.3368835 ], dtype=float32),\n",
       " 'picture frame': array([ 0.46126583, -0.10655415, -0.4743557 , ..., -0.57203424,\n",
       "        -0.14778544,  0.3154033 ], dtype=float32),\n",
       " 'pillow': array([-0.19080904,  0.3607645 , -0.3644184 , ..., -0.09354781,\n",
       "         0.3879156 ,  0.18753529], dtype=float32),\n",
       " 'plant': array([ 0.19120233,  0.23917969,  0.15396243, ..., -0.08370961,\n",
       "         0.04047696,  0.04701484], dtype=float32),\n",
       " 'plate': array([-0.01269488, -0.49310327,  0.0089466 , ...,  0.01077344,\n",
       "         0.417982  , -0.31661862], dtype=float32),\n",
       " 'remote': array([ 0.16861607, -0.08517734, -0.454063  , ..., -0.04014186,\n",
       "         0.3380893 , -0.2006656 ], dtype=float32),\n",
       " 'rock': array([-0.30140176, -0.13926543,  0.19739388, ..., -0.07214085,\n",
       "         0.73540723, -0.08001845], dtype=float32),\n",
       " 'shelf': array([ 0.31388932, -0.24694781, -0.31356245, ..., -0.13021925,\n",
       "        -0.231209  ,  0.05931956], dtype=float32),\n",
       " 'shoe': array([ 0.31391874,  0.12311386, -0.09644461, ..., -0.06752039,\n",
       "         0.3291033 ,  0.05760054], dtype=float32),\n",
       " 'sofa': array([-0.21840909, -0.03647478, -0.19317833, ..., -0.19538017,\n",
       "         0.33617043, -0.04215976], dtype=float32),\n",
       " 'speaker': array([ 0.45696878, -0.08144478, -0.07687257, ...,  0.46830577,\n",
       "         0.08807572,  0.0812949 ], dtype=float32),\n",
       " 'statue': array([ 0.9515998 , -0.65167606,  0.2926641 , ..., -0.25898802,\n",
       "         0.17171155,  0.1416414 ], dtype=float32),\n",
       " 'sunglasses': array([-0.04215012,  0.51181   , -0.5062363 , ...,  0.02978055,\n",
       "         0.5068303 ,  0.05173168], dtype=float32),\n",
       " 'table': array([ 1.0485578 ,  0.13359648, -0.19124688, ..., -0.71442074,\n",
       "        -0.22723065,  0.46504676], dtype=float32),\n",
       " 'television': array([ 0.5396725 , -0.00527304, -0.08823358, ..., -0.24315031,\n",
       "         0.7053649 ,  0.27134448], dtype=float32),\n",
       " 'towel': array([ 0.24073824,  0.17249207, -0.10826052, ..., -0.0698581 ,\n",
       "        -0.09802441,  0.13484974], dtype=float32),\n",
       " 'toy': array([-0.01265862, -0.395125  , -0.35126725, ..., -0.02908937,\n",
       "         0.20228055,  0.15310931], dtype=float32),\n",
       " 'tree': array([-0.05136474, -0.29599062,  0.0765002 , ..., -0.23675656,\n",
       "         0.22440569,  0.4115722 ], dtype=float32),\n",
       " 'umbrella': array([ 0.04574782,  0.23034683, -0.7707215 , ..., -0.08572077,\n",
       "        -0.16603112,  0.46517637], dtype=float32),\n",
       " 'window': array([ 0.65995264, -0.13101675,  0.2966027 , ..., -0.10600672,\n",
       "        -0.06890123, -0.03261884], dtype=float32)}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_class_representations_df['subject_embedding'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformation between sentences\n",
    "\n",
    "If such is the case, we could potentially check if we could learn a mapping to fully invert the sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mapping_results = {}\n",
    "mapping_models = {}\n",
    "\n",
    "def train_linear_mapping_on_embeddings(data, results_dict, models_dict):\n",
    "\n",
    "    X = np.stack(data['embeddings'].apply(lambda x: x[0]).values)\n",
    "    y = np.stack(data['embeddings'].apply(lambda x: x[1]).values)\n",
    "    print(X.shape, y.shape)\n",
    "\n",
    "\n",
    "    linear_model = LinearRegression()\n",
    "    linear_model.fit(X, y)\n",
    "    model_name = f\"linear_model\"\n",
    "    mapping_models[model_name] = linear_model\n",
    "\n",
    "    y_pred = linear_model.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    mapping_results[model_name] = mse\n",
    "    print(f\"MSE for {model_name}: {mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71050, 1024) (71050, 1024)\n",
      "MSE for linear_model: 0.02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dict = {}\n",
    "models_dict = {}\n",
    "\n",
    "train_linear_mapping_on_embeddings(data['Alibaba-NLP_gte-large-en-v1.5.pt'], results_dict, models_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation matrix shape: (1024, 1024)\n",
      "Number of parameters: 1,048,576\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def analyze_transformation(model, X, y):\n",
    "    W = model.coef_  # Get transformation matrix\n",
    "    \n",
    "    # 1. Basic Shape Info\n",
    "    print(f\"Transformation matrix shape: {W.shape}\")\n",
    "    print(f\"Number of parameters: {W.size:,}\")\n",
    "    \n",
    "    # 2. Check prediction quality\n",
    "    y_pred = model.predict(X)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print(f\"\\nPrediction Quality:\")\n",
    "    print(f\"MSE: {mse:.6f}\")\n",
    "    print(f\"R score: {r2:.6f}\")\n",
    "    \n",
    "    # 3. Matrix Properties\n",
    "    print(f\"\\nMatrix Properties:\")\n",
    "    print(f\"Mean coefficient value: {np.mean(W):.6f}\")\n",
    "    print(f\"Std of coefficients: {np.std(W):.6f}\")\n",
    "    print(f\"% of zeros: {(np.abs(W) < 1e-10).mean():.2%}\")\n",
    "    \n",
    "    # 4. Check if mostly diagonal\n",
    "    diagonal_strength = np.abs(np.diag(W)).mean()\n",
    "    off_diagonal_strength = np.abs(W - np.diag(np.diag(W))).mean()\n",
    "    print(f\"\\nDiagonal vs Off-diagonal:\")\n",
    "    print(f\"Diagonal strength: {diagonal_strength:.6f}\")\n",
    "    print(f\"Off-diagonal strength: {off_diagonal_strength:.6f}\")\n",
    "    \n",
    "    # 5. Rank analysis\n",
    "    rank = np.linalg.matrix_rank(W)\n",
    "    print(f\"\\nRank Analysis:\")\n",
    "    print(f\"Matrix rank: {rank} / {W.shape[0]}\")\n",
    "    \n",
    "    # 6. Top singular values\n",
    "    U, s, Vh = np.linalg.svd(W)\n",
    "    print(f\"\\nTop 5 singular values:\")\n",
    "    print(s[:5])\n",
    "\n",
    "# Use it on your model\n",
    "analyze_transformation(\n",
    "    mapping_models['linear_model'],\n",
    "    np.stack(data['Alibaba-NLP_gte-large-en-v1.5.pt']['embeddings'].apply(lambda x: x[0]).values),\n",
    "    np.stack(data['Alibaba-NLP_gte-large-en-v1.5.pt']['embeddings'].apply(lambda x: x[1]).values)\n",
    ")\n",
    "\n",
    "# Optional: Check for overfitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nGeneralization Check:\")\n",
    "print(f\"Train MSE: {mean_squared_error(y_train, model.predict(X_train)):.6f}\")\n",
    "print(f\"Test MSE: {mean_squared_error(y_test, model.predict(X_test)):.6f}\")\n",
    "\n",
    "# Check if it's mostly diagonal\n",
    "diagonal_strength = np.abs(np.diag(mapping_models['linear_model'].coef_)).mean()\n",
    "off_diagonal_strength = np.abs(mapping_models['linear_model'].coef_ - np.diag(np.diag(mapping_models['linear_model'].coef_))).mean()\n",
    "print(f\"Diagonal vs off-diagonal strength: {diagonal_strength:.3f} vs {off_diagonal_strength:.3f}\")\n",
    "\n",
    "# Check the rank\n",
    "rank = np.linalg.matrix_rank(mapping_models['linear_model'].coef_)\n",
    "print(f\"Rank of transformation: {rank} / 1024\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain a linear mapping between the embeddings of the subject and object. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax & Transformation \n",
    "\n",
    "We have a representation for both could take the representation of subject and object and asess if there is any change. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compositionality \n",
    "\n",
    "We now have a representation for all the words and all the relations, we have to create this mapping. We can show that it extends outside. It is already very clear that we can decompose the representation into specific words. But also the position of the subject. \n",
    "\n",
    "How would we prove full compositionality ? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now be confident in a form  of compositionality. The transformation from object to subject can be used to build sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
