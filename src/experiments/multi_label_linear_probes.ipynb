{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "MODELS = [\n",
    "    \"Alibaba-NLP/gte-large-en-v1.5\",\n",
    "    \"intfloat/multilingual-e5-large\",\n",
    "    \"sentence-transformers/all-mpnet-base-v2\",\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "]\n",
    "\n",
    "DATA_PATH = '../data'\n",
    "RELATIONS_JSON_PATH = '../data/relations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully!\n",
      "Loaded data type: <class 'list'>\n",
      "List length: 142100\n",
      "First item: {'sentence': 'The table is above the chair.', 'relation': 'above', 'subject': 'table', 'object': 'chair', 'embedding': array([ 0.32811892,  0.24800315,  0.28813255, ..., -0.2839055 ,\n",
      "       -0.95515853, -0.04943762], shape=(1024,), dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "file_path = \"../data/Alibaba-NLP_gte-large-en-v1.5.pt\"\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    data = torch.load(file_path, map_location=\"cpu\")  # Load on CPU to avoid GPU issues\n",
    "    print(\"Data loaded successfully!\")\n",
    "\n",
    "    # Print the type of the loaded object\n",
    "    print(\"Loaded data type:\", type(data))\n",
    "    print(\"List length:\", len(data))\n",
    "    print(\"First item:\", data[0])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(RELATIONS_JSON_PATH, 'r') as f:\n",
    "    relations = json.load(f)['spatial_relations']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_lookup(relations):\n",
    "    relations_lookup = {}\n",
    "    for category, category_pairs in relations.items():\n",
    "        for first, second in category_pairs:\n",
    "            relations_lookup[first] = {'category': category, 'opposite': second, 'position': 0}\n",
    "            relations_lookup[second] = {'category': category, 'opposite': first, 'position': 1}\n",
    "    return relations_lookup\n",
    "\n",
    "relations_lookup = get_relations_lookup(relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_for_model(model_name):\n",
    "    #label = \"subject\", \"object\", or \"relation\"\n",
    "    embeddings = []\n",
    "    sub_labels = []\n",
    "    ob_labels = []\n",
    "    rel_labels = []\n",
    "    raw_data = torch.load(f'{DATA_PATH}/{model_name.replace(\"/\", \"_\")}.pt', weights_only=False)\n",
    "    for data_point in raw_data:\n",
    "        embeddings.append(data_point['embedding'])\n",
    "        sub_labels.append(data_point['subject'])\n",
    "        ob_labels.append(data_point['object'])\n",
    "        rel_labels.append(data_point['relation'])\n",
    "    return np.array(embeddings), np.array(sub_labels).reshape(-1, 1), np.array(ob_labels).reshape(-1, 1), np.array(rel_labels).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.32811892  0.24800315  0.28813255 ... -0.2839055  -0.95515853\n",
      " -0.04943762] ['table'] ['chair'] ['above']\n"
     ]
    }
   ],
   "source": [
    "X, y_sub, y_ob, y_rel = load_embeddings_for_model(MODELS[0])\n",
    "print(X[0],y_sub[0],y_ob[0],y_rel[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training probe for Alibaba-NLP/gte-large-en-v1.5...\n",
      "Accuracy for Alibaba-NLP/gte-large-en-v1.5: Joint 0.99, Subject 1.00,           Object 0.99, Relation 0.99\n",
      "Training probe for intfloat/multilingual-e5-large...\n",
      "Accuracy for intfloat/multilingual-e5-large: Joint 1.00, Subject 1.00,           Object 1.00, Relation 1.00\n",
      "Training probe for sentence-transformers/all-mpnet-base-v2...\n",
      "Accuracy for sentence-transformers/all-mpnet-base-v2: Joint 1.00, Subject 1.00,           Object 1.00, Relation 1.00\n",
      "Training probe for sentence-transformers/all-MiniLM-L6-v2...\n",
      "Accuracy for sentence-transformers/all-MiniLM-L6-v2: Joint 1.00, Subject 1.00,           Object 1.00, Relation 1.00\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "models = {}\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "\n",
    "for model_name in MODELS:\n",
    "    print(f\"Training probe for {model_name}...\")\n",
    "    X, y_sub, y_ob, y_rel = load_embeddings_for_model(model_name)\n",
    "    y_sub_encoded = one_hot_encoder.fit_transform(y_sub).todense()\n",
    "    y_ob_encoded = one_hot_encoder.fit_transform(y_ob).todense()\n",
    "    y_rel_encoded = one_hot_encoder.fit_transform(y_rel).todense()\n",
    "    X_train, X_test, y_sub_train, y_sub_test, y_ob_train, y_ob_test, y_rel_train, y_rel_test = \\\n",
    "        train_test_split(X, y_sub_encoded, y_ob_encoded, y_rel_encoded, test_size=0.2) \n",
    "\n",
    "    y_sub_train = np.asarray(y_sub_train)\n",
    "    y_sub_test = np.asarray(y_sub_test)\n",
    "    y_ob_train = np.asarray(y_ob_train)\n",
    "    y_ob_test = np.asarray(y_ob_test)\n",
    "    y_rel_train = np.asarray(y_rel_train)\n",
    "    y_rel_test = np.asarray(y_rel_test)\n",
    "    \n",
    "    # Train probes\n",
    "    clf_sub = MLPClassifier(activation='identity')\n",
    "    clf_sub.fit(X_train, y_sub_train)\n",
    "\n",
    "    clf_ob = MLPClassifier(activation='identity')\n",
    "    clf_ob.fit(X_train, y_ob_train)\n",
    "\n",
    "    clf_rel = MLPClassifier(activation='identity')\n",
    "    clf_rel.fit(X_train, y_rel_train)\n",
    "    models[model_name] = (clf_sub, clf_ob, clf_rel)\n",
    "\n",
    "    y_sub_pred = clf_sub.predict(X_test)\n",
    "    y_ob_pred = clf_ob.predict(X_test)\n",
    "    y_rel_pred = clf_rel.predict(X_test)\n",
    "\n",
    "    accuracy_sub = accuracy_score(y_sub_test, y_sub_pred)\n",
    "    accuracy_ob = accuracy_score(y_ob_test, y_ob_pred)\n",
    "    accuracy_rel = accuracy_score(y_rel_test, y_rel_pred)\n",
    "    \n",
    "    # Check correctness for each component separately\n",
    "    sub_correct = np.argmax(y_sub_pred, axis=1) == np.argmax(y_sub_test, axis=1)\n",
    "    ob_correct = np.argmax(y_ob_pred, axis=1) == np.argmax(y_ob_test, axis=1)\n",
    "    rel_correct = np.argmax(y_rel_pred, axis=1) == np.argmax(y_rel_test, axis=1)\n",
    "\n",
    "    # Compute joint correctness (all three correct for each example)\n",
    "    joint_correct = sub_correct & ob_correct & rel_correct\n",
    "\n",
    "    # Compute joint accuracy\n",
    "    joint_accuracy = np.mean(joint_correct)\n",
    "\n",
    "\n",
    "    results[model_name] = {\"accuracy_sub\": accuracy_sub, \"accuracy_ob\": accuracy_ob,\n",
    "                           \"accuracy_rel\": accuracy_rel, \"joint_accuracy\": joint_accuracy}\n",
    "    print(f\"Accuracy for {model_name}: Joint {joint_accuracy:.2f}, Subject {accuracy_sub:.2f}, \\\n",
    "          Object {accuracy_ob:.2f}, Relation {accuracy_rel:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
