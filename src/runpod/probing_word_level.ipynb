{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LMBRhdDbKgwn"
   },
   "source": [
    "# Supervised Dictionary Learning for Sentence Decomposition\n",
    "\n",
    "We have had success with linear probes. We can now try to further decompose it into further atoms, which would show broader structure.\n",
    "\n",
    "In order to align these atoms with interpretable properties, we train the dictionary with a classification task added to the reconstruction loss.\n",
    "\n",
    "\n",
    "The goal is to check if we can linearly decompose the embedding back into words with the part of speech and dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uZYHKkKH6yD",
    "outputId": "54cbba57-a020-4461-cf33-0f6c48171b5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.9.0)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.24.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Downloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests (from transformers)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2023.4.0)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Downloading aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp->datasets)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Downloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Downloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (69 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hINFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.29.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.29.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Downloading huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0 (from datasets)\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.14-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-19.0.1-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m145.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.5.3-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (471 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.6/471.6 kB\u001b[0m \u001b[31m155.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m194.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 kB\u001b[0m \u001b[31m111.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.8/129.8 kB\u001b[0m \u001b[31m72.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading propcache-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (206 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.6/206.6 kB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m165.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m135.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m132.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, xxhash, tzdata, safetensors, requests, pyarrow, propcache, multidict, fsspec, frozenlist, dill, async-timeout, aiohappyeyeballs, yarl, pandas, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.31.0\n",
      "    Uninstalling requests-2.31.0:\n",
      "      Successfully uninstalled requests-2.31.0\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.4.0\n",
      "    Uninstalling fsspec-2023.4.0:\n",
      "      Successfully uninstalled fsspec-2023.4.0\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 async-timeout-5.0.1 datasets-3.5.0 dill-0.3.8 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.3 multidict-6.2.0 multiprocess-0.70.16 pandas-2.2.3 propcache-0.3.1 pyarrow-19.0.1 pytz-2025.2 requests-2.32.3 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.50.3 tzdata-2025.2 xxhash-3.5.0 yarl-1.18.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install stanza -q\n",
    "!pip install nltk -q\n",
    "!pip install transformers datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BDwC3MJktMHw",
    "outputId": "f01fcf22-2e25-46ea-9c3e-476a1983caae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97f09784acf4b088ce38783d76735cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 22:22:07 INFO: Downloaded file to /root/stanza_resources/resources.json\n",
      "2025-03-28 22:22:07 INFO: Downloading default packages for language: en (English) ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2ec4a434ab48769b3ce86af7c84995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip:   0%|          | …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-28 22:22:11 INFO: Downloaded file to /root/stanza_resources/en/default.zip\n",
      "2025-03-28 22:22:14 INFO: Finished downloading models and saved to /root/stanza_resources\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "nltk.download('brown')\n",
    "import stanza\n",
    "from nltk.corpus import brown\n",
    "stanza.download('en')\n",
    "\n",
    "\n",
    "def reconstruct_sentence(tokens):\n",
    "    sentence = \" \".join(tokens)\n",
    "    sentence = sentence.replace('``', '').replace(\"''\", \"\").replace(\n",
    "        \" ,\", \",\").replace(\" .\", \".\").replace(\" ?\", \"?\").replace(\" !\", \"!\")\n",
    "    return sentence\n",
    "\n",
    "brown_sentences = [reconstruct_sentence(tokens) for tokens in brown.sents()]\n",
    "brown_sentences = brown_sentences[:20000]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a8716806f14becb91bd7980176f791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3edd038dfcbb4002b8d2f5d2a5d1c0a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5fa499510c34888844961e02719b4f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e2682dd5972405787680595052df3a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c338e750b343df946c9b24e6e09761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f739d8760899477d997002fccd174bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import stanza\n",
    "import pandas as pd\n",
    "\n",
    "# Load tokenizer and model\n",
    "model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913,
     "referenced_widgets": [
      "3e7a458b43e8477b8a6557b839699caf",
      "474ef1a806064bb49dcb34c223d4f95e",
      "fc430d793af34d76b87cad97b499601c",
      "6a1a78c312fc4557b63aeaa7f520265b",
      "3b19fe70c21b4f6193aef5bdf4314c1d",
      "eebcc947f0424443b2333c62dc8fbf1e",
      "0ff97cfa2fba4521bc5e0941595ad4b8",
      "5f4aa45ac6c847889ad7391e397d3092",
      "b99dc4d3a86a4c1cb4869a231fd014c4",
      "9ee2ee31d6544832bdd1ac654cf70a8c",
      "72b0a66f4e5c4af9b04f06245350a92b",
      "778843fdc46243bc99c48bd8d83c6f69",
      "5e026def0b3b455a8f9025eeb6ee1b92",
      "44dcec911c734f20836522fd428ed5a1",
      "20a0c56070a34a57bfbf5644790825e3",
      "0db1958bb8e64c0ea189244d76988db9",
      "9bc41f2f61244dc3ac3dfa88b1e8b271",
      "dc297f854e054e32af42fe3a42195160",
      "824389fafdcc4d6996da55884984b7fe",
      "0d795275e8364fcba722c558bbac784d",
      "e1582f9f01524c06a22292748b25faa3",
      "ccc1e152e6d046edac82397ba22c147e"
     ]
    },
    "id": "fDTmJ_axNjnX",
    "outputId": "1b73b09c-8f4b-478f-81ba-50bf61f88888",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587b3fc017ac4af98ddee84546efa2c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 11:15:17 INFO: Downloaded file to /root/stanza_resources/resources.json\n",
      "2025-03-27 11:15:17 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-03-27 11:15:18 INFO: File exists: /root/stanza_resources/en/default.zip\n",
      "2025-03-27 11:15:21 INFO: Finished downloading models and saved to /root/stanza_resources\n",
      "2025-03-27 11:15:21 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e0e805590344d72ae7059847e3ae08e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 11:15:21 INFO: Downloaded file to /root/stanza_resources/resources.json\n",
      "2025-03-27 11:15:21 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-03-27 11:15:22 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| pos       | combined_charlm   |\n",
      "| lemma     | combined_nocharlm |\n",
      "| depparse  | combined_charlm   |\n",
      "=================================\n",
      "\n",
      "2025-03-27 11:15:22 INFO: Using device: cuda\n",
      "2025-03-27 11:15:22 INFO: Loading: tokenize\n",
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "2025-03-27 11:15:22 INFO: Loading: mwt\n",
      "2025-03-27 11:15:22 INFO: Loading: pos\n",
      "2025-03-27 11:15:23 INFO: Loading: lemma\n",
      "2025-03-27 11:15:24 INFO: Loading: depparse\n",
      "2025-03-27 11:15:24 INFO: Done loading processors!\n",
      "Processing sentences: 100%|██████████| 20000/20000 [31:05<00:00, 10.72it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load stanza for offset alignment\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline('en', processors='tokenize,pos,depparse,lemma')\n",
    "\n",
    "def get_word_embeddings_aligned(sentence: str):\n",
    "    \"\"\"\n",
    "    Given a sentence, aligns subword embeddings from MiniLM to words using char offsets from Stanza.\n",
    "    Returns a list of dicts with word, embedding, POS, dependency, and position.\n",
    "    \"\"\"\n",
    "    doc = nlp(sentence)\n",
    "    word_spans = [(word.text, word.start_char, word.end_char, word.upos, word.deprel) \n",
    "                  for sent in doc.sentences for word in sent.words]\n",
    "\n",
    "    # Tokenize with offset mapping, no special tokens\n",
    "    encoding = tokenizer(\n",
    "        sentence,\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\",\n",
    "        add_special_tokens=False\n",
    "    )\n",
    "    offsets = encoding[\"offset_mapping\"][0].tolist()\n",
    "    input_ids = encoding[\"input_ids\"]\n",
    "\n",
    "    # Get subword embeddings\n",
    "    with torch.no_grad():\n",
    "        output = model(**{k: v for k, v in encoding.items() if k != 'offset_mapping'})\n",
    "        subword_embeddings = output.last_hidden_state.squeeze(0)  # [seq_len, dim]\n",
    "\n",
    "    # Align subwords to words\n",
    "    aligned_data = []\n",
    "    for i, (word, w_start, w_end, upos, deprel) in enumerate(word_spans):\n",
    "        matching_sub_idxs = [j for j, (s, e) in enumerate(offsets) if s < w_end and e > w_start and s != e]\n",
    "\n",
    "        if matching_sub_idxs:\n",
    "            embs = [subword_embeddings[j] for j in matching_sub_idxs]\n",
    "            word_embedding = torch.stack(embs).mean(dim=0)\n",
    "            aligned_data.append({\n",
    "                \"word\": word,\n",
    "                \"embedding\": word_embedding,\n",
    "                \"pos\": upos,\n",
    "                \"dep\": deprel,\n",
    "                \"position\": i\n",
    "            })\n",
    "\n",
    "    return aligned_data\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "all_rows = []\n",
    "for i, sent in tqdm(enumerate(brown_sentences), total=len(brown_sentences), desc=\"Processing sentences\"):\n",
    "    try:\n",
    "        aligned = get_word_embeddings_aligned(sent)\n",
    "        for row in aligned:\n",
    "            row[\"sentence_id\"] = i\n",
    "            row[\"sentence\"] = sent\n",
    "            all_rows.append(row)\n",
    "    except: \n",
    "        continue\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(all_rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(\"./dataset.pkl\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the DataFrame from a pickle file\n",
    "df = pd.read_pickle(\"./dataset.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaptative Softwax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31484"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"word\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - Epoch 1, Loss: 4730.9234\n",
      "POS - Epoch 2, Loss: 3247.7045\n",
      "POS - Epoch 3, Loss: 3069.8149\n",
      "POS - Epoch 4, Loss: 2991.8502\n",
      "POS - Epoch 5, Loss: 2948.3470\n",
      "POS - Epoch 6, Loss: 2920.6060\n",
      "POS - Epoch 7, Loss: 2901.9377\n",
      "POS - Epoch 8, Loss: 2887.0535\n",
      "POS - Epoch 9, Loss: 2876.1811\n",
      "POS - Epoch 10, Loss: 2868.2626\n",
      "DEP - Epoch 1, Loss: 9753.6313\n",
      "DEP - Epoch 2, Loss: 7845.6147\n",
      "DEP - Epoch 3, Loss: 7579.3977\n",
      "DEP - Epoch 4, Loss: 7462.0545\n",
      "DEP - Epoch 5, Loss: 7393.7948\n",
      "DEP - Epoch 6, Loss: 7352.5016\n",
      "DEP - Epoch 7, Loss: 7323.5441\n",
      "DEP - Epoch 8, Loss: 7301.7198\n",
      "DEP - Epoch 9, Loss: 7285.5186\n",
      "DEP - Epoch 10, Loss: 7273.5649\n",
      "POSITION - Epoch 1, Loss: 19297.2871\n",
      "POSITION - Epoch 2, Loss: 16700.9510\n",
      "POSITION - Epoch 3, Loss: 16192.9907\n",
      "POSITION - Epoch 4, Loss: 15955.9640\n",
      "POSITION - Epoch 5, Loss: 15813.7989\n",
      "POSITION - Epoch 6, Loss: 15723.1971\n",
      "POSITION - Epoch 7, Loss: 15657.1624\n",
      "POSITION - Epoch 8, Loss: 15610.5736\n",
      "POSITION - Epoch 9, Loss: 15572.2952\n",
      "POSITION - Epoch 10, Loss: 15542.8545\n",
      "WORD - Epoch 1, Loss: 30224.9943\n",
      "WORD - Epoch 2, Loss: 14575.9780\n",
      "WORD - Epoch 3, Loss: 11262.3291\n",
      "WORD - Epoch 4, Loss: 9647.6431\n",
      "WORD - Epoch 5, Loss: 8721.4151\n",
      "WORD - Epoch 6, Loss: 8112.7963\n",
      "WORD - Epoch 7, Loss: 7700.6792\n",
      "WORD - Epoch 8, Loss: 7445.3065\n",
      "WORD - Epoch 9, Loss: 7279.9358\n",
      "WORD - Epoch 10, Loss: 7141.1885\n",
      "\n",
      "--- Evaluation ---\n",
      "POS Accuracy:       87.38%\n",
      "DEP Accuracy:       68.91%\n",
      "POSITION Accuracy:  31.02%\n",
      "WORD Accuracy:      84.64%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ---- Prepare Data ----\n",
    "X = torch.stack(df['embedding'].tolist())\n",
    "\n",
    "le_pos = LabelEncoder().fit(df[\"pos\"])\n",
    "le_dep = LabelEncoder().fit(df[\"dep\"])\n",
    "le_word = LabelEncoder().fit(df[\"word\"])\n",
    "\n",
    "y_pos = torch.tensor(le_pos.transform(df['pos'].values))\n",
    "y_dep = torch.tensor(le_dep.transform(df['dep'].values))\n",
    "y_word = torch.tensor(le_word.transform(df['word'].values))\n",
    "y_position = torch.tensor(df['position'].values)\n",
    "\n",
    "# ---- Define Probes ----\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class AdaptiveSoftmaxProbe(nn.Module):\n",
    "    def __init__(self, input_dim, n_classes):\n",
    "        super().__init__()\n",
    "        cutoffs = [1000, min(10000, n_classes - 2)] if n_classes > 10000 else [1000]\n",
    "        self.adaptive_softmax = nn.AdaptiveLogSoftmaxWithLoss(\n",
    "            in_features=input_dim,\n",
    "            n_classes=n_classes,\n",
    "            cutoffs=cutoffs,\n",
    "            div_value=4.0\n",
    "        )\n",
    "\n",
    "    def forward(self, x, target=None):\n",
    "        if target is not None:\n",
    "            return self.adaptive_softmax(x, target)\n",
    "        else:\n",
    "            return self.adaptive_softmax.log_prob(x)\n",
    "\n",
    "# ---- Training Functions ----\n",
    "def train_linear_probe(X, y, num_classes, task_name=\"TASK\", epochs=10):\n",
    "    model = LinearProbe(X.shape[1], num_classes)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"{task_name} - Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_adaptive_probe(X, y, num_classes, task_name=\"TASK\", epochs=10):\n",
    "    model = AdaptiveSoftmaxProbe(X.shape[1], num_classes)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(xb, yb)\n",
    "            loss = out.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"{task_name} - Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# ---- Evaluation Functions ----\n",
    "def evaluate_linear_probe(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).argmax(dim=1)\n",
    "        accuracy = (preds == y).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "def evaluate_adaptive_probe(model, X, y, batch_size=64):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    dataset = DataLoader(TensorDataset(X, y), batch_size=batch_size)\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in dataset:\n",
    "            out = model(xb, yb)\n",
    "            # Get predicted class by getting the max log probability from log_prob(x)\n",
    "            # Even though log_prob is memory-intensive, we can do it in batches.\n",
    "            log_probs = model.adaptive_softmax.log_prob(xb)\n",
    "            preds = log_probs.argmax(dim=1)\n",
    "            correct += (preds == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# ---- Train Probes ----\n",
    "pos_model = train_linear_probe(X, y_pos, len(le_pos.classes_), task_name=\"POS\")\n",
    "dep_model = train_linear_probe(X, y_dep, len(le_dep.classes_), task_name=\"DEP\")\n",
    "position_model = train_linear_probe(X, y_position, y_position.max().item() + 1, task_name=\"POSITION\")\n",
    "word_model = train_adaptive_probe(X, y_word, len(le_word.classes_), task_name=\"WORD\")\n",
    "\n",
    "# ---- Evaluate All Probes ----\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "print(f\"POS Accuracy:       {evaluate_linear_probe(pos_model, X, y_pos):.2%}\")\n",
    "print(f\"DEP Accuracy:       {evaluate_linear_probe(dep_model, X, y_dep):.2%}\")\n",
    "print(f\"POSITION Accuracy:  {evaluate_linear_probe(position_model, X, y_position):.2%}\")\n",
    "print(f\"WORD Accuracy:      {evaluate_adaptive_probe(word_model, X, y_word):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rcW2lq9Q3io"
   },
   "source": [
    "# MODEL PROBE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZETOmlp5Q4wG",
    "outputId": "2f9ed6c5-258b-4633-870c-2a1c7485abe4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - Epoch 1, Loss: 4740.1016\n",
      "POS - Epoch 2, Loss: 3248.5331\n",
      "POS - Epoch 3, Loss: 3069.9618\n",
      "POS - Epoch 4, Loss: 2992.9384\n",
      "POS - Epoch 5, Loss: 2948.8804\n",
      "POS - Epoch 6, Loss: 2920.8930\n",
      "POS - Epoch 7, Loss: 2901.8045\n",
      "POS - Epoch 8, Loss: 2887.5567\n",
      "POS - Epoch 9, Loss: 2876.2220\n",
      "POS - Epoch 10, Loss: 2868.3626\n",
      "DEP - Epoch 1, Loss: 9744.6328\n",
      "DEP - Epoch 2, Loss: 7843.7364\n",
      "DEP - Epoch 3, Loss: 7578.9932\n",
      "DEP - Epoch 4, Loss: 7461.9076\n",
      "DEP - Epoch 5, Loss: 7394.7150\n",
      "DEP - Epoch 6, Loss: 7351.7902\n",
      "DEP - Epoch 7, Loss: 7324.2117\n",
      "DEP - Epoch 8, Loss: 7300.6181\n",
      "DEP - Epoch 9, Loss: 7285.8807\n",
      "DEP - Epoch 10, Loss: 7273.1770\n",
      "WORD - Epoch 1, Loss: 22264.9924\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = torch.stack(df['embedding'].tolist())\n",
    "\n",
    "le_pos = LabelEncoder().fit(df[\"pos\"])\n",
    "le_dep = LabelEncoder().fit(df[\"dep\"])\n",
    "le_word = LabelEncoder().fit(df[\"word\"])\n",
    "\n",
    "y_pos = torch.tensor(le_pos.transform(df['pos'].values))\n",
    "y_dep = torch.tensor(le_dep.transform(df['dep'].values))\n",
    "y_word = torch.tensor(le_word.transform(df['word'].values))\n",
    "y_position = torch.tensor(df['position'].values)\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_probe(X, y, num_classes, task_name=\"TASK\", epochs=10):\n",
    "    model = LinearProbe(X.shape[1], num_classes)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(xb)\n",
    "            loss = loss_fn(logits, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"{task_name} - Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return model\n",
    "\n",
    "def evaluate_probe(model, X, y):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds = model(X).argmax(dim=1)\n",
    "        accuracy = (preds == y).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "pos_model = train_probe(X, y_pos, len(le_pos.classes_), task_name=\"POS\")\n",
    "dep_model = train_probe(X, y_dep, len(le_dep.classes_), task_name=\"DEP\")\n",
    "word_model = train_probe(X, y_word, len(le_word.classes_), task_name=\"WORD\")\n",
    "position_model = train_probe(X, y_position, y_position.max().item() + 1, task_name=\"POSITION\")\n",
    "\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "print(f\"POS Accuracy:       {evaluate_probe(pos_model, X, y_pos):.2%}\")\n",
    "print(f\"DEP Accuracy:       {evaluate_probe(dep_model, X, y_dep):.2%}\")\n",
    "print(f\"WORD Accuracy:      {evaluate_probe(word_model, X, y_word):.2%}\")\n",
    "print(f\"POSITION Accuracy:  {evaluate_probe(position_model, X, y_position):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WXu0QaCVTuoh",
    "outputId": "1840005e-b916-4a21-e7d6-642cf2907202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS - Epoch 1, Loss: 5085862.2582\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 79\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# 6. Train dictionary-augmented probes\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m pos_model, pos_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_probe_with_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mle_pos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses_\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m dep_model, dep_dict \u001b[38;5;241m=\u001b[39m train_probe_with_dictionary(X, y_dep, \u001b[38;5;28mlen\u001b[39m(le_dep\u001b[38;5;241m.\u001b[39mclasses_), task_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m word_model, word_dict \u001b[38;5;241m=\u001b[39m train_probe_with_dictionary(X, y_word, \u001b[38;5;28mlen\u001b[39m(le_word\u001b[38;5;241m.\u001b[39mclasses_), task_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWORD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 52\u001b[0m, in \u001b[0;36mtrain_probe_with_dictionary\u001b[0;34m(X, y, num_classes, task_name, dict_size, epochs)\u001b[0m\n\u001b[1;32m     50\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xb, yb \u001b[38;5;129;01min\u001b[39;00m loader:\n\u001b[0;32m---> 52\u001b[0m     codes, recon \u001b[38;5;241m=\u001b[39m \u001b[43mdict_learner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     logits \u001b[38;5;241m=\u001b[39m probe(codes)\n\u001b[1;32m     55\u001b[0m     loss_recon \u001b[38;5;241m=\u001b[39m recon_loss_fn(recon, xb)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m, in \u001b[0;36mDictionaryLearner.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     codes \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdictionary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     recon \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(codes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdictionary)\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codes, recon\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = torch.stack(df['embedding'].tolist())\n",
    "\n",
    "le_pos = LabelEncoder().fit(df[\"pos\"])\n",
    "le_dep = LabelEncoder().fit(df[\"dep\"])\n",
    "le_word = LabelEncoder().fit(df[\"word\"])\n",
    "\n",
    "y_pos = torch.tensor(le_pos.transform(df['pos'].values))\n",
    "y_dep = torch.tensor(le_dep.transform(df['dep'].values))\n",
    "y_word = torch.tensor(le_word.transform(df['word'].values))\n",
    "y_position = torch.tensor(df['position'].values)\n",
    "\n",
    "class DictionaryLearner(nn.Module):\n",
    "    def __init__(self, input_dim, dict_size):\n",
    "        super().__init__()\n",
    "        self.dictionary = nn.Parameter(torch.randn(dict_size, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        codes = torch.matmul(x, self.dictionary.T)\n",
    "        recon = torch.matmul(codes, self.dictionary)\n",
    "        return codes, recon\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_probe_with_dictionary(X, y, num_classes, task_name=\"TASK\", dict_size=128, epochs=10):\n",
    "    dict_learner = DictionaryLearner(X.shape[1], dict_size)\n",
    "    probe = LinearProbe(dict_size, num_classes)\n",
    "\n",
    "    recon_loss_fn = nn.MSELoss()\n",
    "    clf_loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(list(dict_learner.parameters()) + list(probe.parameters()), lr=1e-3)\n",
    "\n",
    "    dataset = TensorDataset(X, y)\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in loader:\n",
    "            codes, recon = dict_learner(xb)\n",
    "            logits = probe(codes)\n",
    "\n",
    "            loss_recon = recon_loss_fn(recon, xb)\n",
    "            loss_clf = clf_loss_fn(logits, yb)\n",
    "            loss = loss_recon + loss_clf\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"{task_name} - Epoch {epoch+1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "    return probe, dict_learner\n",
    "\n",
    "# 5. Evaluation function\n",
    "def evaluate_probe(model, dict_learner, X, y):\n",
    "    model.eval()\n",
    "    dict_learner.eval()\n",
    "    with torch.no_grad():\n",
    "        codes, _ = dict_learner(X)\n",
    "        preds = model(codes).argmax(dim=1)\n",
    "        accuracy = (preds == y).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "# 6. Train dictionary-augmented probes\n",
    "pos_model, pos_dict = train_probe_with_dictionary(X, y_pos, len(le_pos.classes_), task_name=\"POS\")\n",
    "dep_model, dep_dict = train_probe_with_dictionary(X, y_dep, len(le_dep.classes_), task_name=\"DEP\")\n",
    "word_model, word_dict = train_probe_with_dictionary(X, y_word, len(le_word.classes_), task_name=\"WORD\")\n",
    "position_model, posn_dict = train_probe_with_dictionary(X, y_position, y_position.max().item() + 1, task_name=\"POSITION\")\n",
    "\n",
    "# 7. Evaluate all\n",
    "print(\"\\n--- Evaluation ---\")\n",
    "print(f\"POS Accuracy:       {evaluate_probe(pos_model, pos_dict, X, y_pos):.2%}\")\n",
    "print(f\"DEP Accuracy:       {evaluate_probe(dep_model, dep_dict, X, y_dep):.2%}\")\n",
    "print(f\"WORD Accuracy:      {evaluate_probe(word_model, word_dict, X, y_word):.2%}\")\n",
    "print(f\"POSITION Accuracy:  {evaluate_probe(position_model, posn_dict, X, y_position):.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "500zGDrnUnVH"
   },
   "source": [
    "# Shared Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nF6gJ_7_TuuE",
    "outputId": "5a08771b-0774-4cdd-ea97-4ee23dc00767"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X = torch.stack(df['embedding'].tolist())\n",
    "\n",
    "le_pos = LabelEncoder().fit(df[\"pos\"])\n",
    "le_dep = LabelEncoder().fit(df[\"dep\"])\n",
    "le_word = LabelEncoder().fit(df[\"word\"])\n",
    "\n",
    "y_pos = torch.tensor(le_pos.transform(df['pos'].values))\n",
    "y_dep = torch.tensor(le_dep.transform(df['dep'].values))\n",
    "y_word = torch.tensor(le_word.transform(df['word'].values))\n",
    "y_position = torch.tensor(df['position'].values)\n",
    "\n",
    "class DictionaryLearner(nn.Module):\n",
    "    def __init__(self, input_dim, dict_size):\n",
    "        super().__init__()\n",
    "        self.dictionary = nn.Parameter(torch.randn(dict_size, input_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        codes = torch.matmul(x, self.dictionary.T)\n",
    "        recon = torch.matmul(codes, self.dictionary)\n",
    "        return codes, recon\n",
    "\n",
    "class LinearProbe(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "def train_multitask_probes_with_shared_dictionary(X, y_dict, probes, dict_learner, epochs=10):\n",
    "    loss_fn_cls = nn.CrossEntropyLoss()\n",
    "    loss_fn_recon = nn.MSELoss()\n",
    "    probe_params = []\n",
    "    for probe in probes.values():\n",
    "        probe_params += list(probe.parameters())\n",
    "\n",
    "    optimizer = optim.Adam(probe_params + list(dict_learner.parameters()), lr=1e-3)\n",
    "    dataset = TensorDataset(X, y_dict['pos'], y_dict['dep'], y_dict['word'], y_dict['position'])\n",
    "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, y_pos_b, y_dep_b, y_word_b, y_posn_b in loader:\n",
    "            codes, recon = dict_learner(xb)\n",
    "\n",
    "            loss_pos = loss_fn_cls(probes['pos'](codes), y_pos_b)\n",
    "            loss_dep = loss_fn_cls(probes['dep'](codes), y_dep_b)\n",
    "            loss_word = loss_fn_cls(probes['word'](codes), y_word_b)\n",
    "            loss_posn = loss_fn_cls(probes['position'](codes), y_posn_b)\n",
    "            loss_recon = loss_fn_recon(recon, xb)\n",
    "\n",
    "            total = loss_pos + loss_dep + loss_word + loss_posn + loss_recon\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += total.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, Total Loss: {total_loss:.4f}\")\n",
    "\n",
    "def evaluate_probe(model, dict_learner, X, y):\n",
    "    model.eval()\n",
    "    dict_learner.eval()\n",
    "    with torch.no_grad():\n",
    "        codes, _ = dict_learner(X)\n",
    "        preds = model(codes).argmax(dim=1)\n",
    "        accuracy = (preds == y).float().mean().item()\n",
    "    return accuracy\n",
    "\n",
    "dict_size = 128\n",
    "shared_dict = DictionaryLearner(X.shape[1], dict_size)\n",
    "\n",
    "probes = {\n",
    "    'pos': LinearProbe(dict_size, len(le_pos.classes_)),\n",
    "    'dep': LinearProbe(dict_size, len(le_dep.classes_)),\n",
    "    'word': LinearProbe(dict_size, len(le_word.classes_)),\n",
    "    'position': LinearProbe(dict_size, y_position.max().item() + 1),\n",
    "}\n",
    "\n",
    "y_dict = {\n",
    "    'pos': y_pos,\n",
    "    'dep': y_dep,\n",
    "    'word': y_word,\n",
    "    'position': y_position,\n",
    "}\n",
    "\n",
    "train_multitask_probes_with_shared_dictionary(X, y_dict, probes, shared_dict)\n",
    "\n",
    "print(\"\\n--- Evaluation with Shared Dictionary ---\")\n",
    "print(f\"POS Accuracy:       {evaluate_probe(probes['pos'], shared_dict, X, y_pos):.2%}\")\n",
    "print(f\"DEP Accuracy:       {evaluate_probe(probes['dep'], shared_dict, X, y_dep):.2%}\")\n",
    "print(f\"WORD Accuracy:      {evaluate_probe(probes['word'], shared_dict, X, y_word):.2%}\")\n",
    "print(f\"POSITION Accuracy:  {evaluate_probe(probes['position'], shared_dict, X, y_position):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "probes_to_pickle = {\n",
    "    'pos_model': pos_model, \n",
    "    'dep_model': dep_model, \n",
    "    'position_model': position_model,\n",
    "    'word_model': word_model\n",
    "}\n",
    "\n",
    "with open('probes.pkl', 'wb') as f:\n",
    "    pickle.dump(probes_to_pickle, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "059efd90469b40b7902021b5c9b7ffe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8b7a6abb0c3c4483b62403eef3b28e78",
       "IPY_MODEL_58243208c87c45c6be2b80fd42b0304f",
       "IPY_MODEL_b249c7cd630a440a9d1384b0e78e5166"
      ],
      "layout": "IPY_MODEL_f58a69854c0a4f3cbc6ec9848c372694"
     }
    },
    "0a8b0f82c6324bcd8929469301b3fa64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d795275e8364fcba722c558bbac784d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0db1958bb8e64c0ea189244d76988db9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0ff97cfa2fba4521bc5e0941595ad4b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "121ec3c89a334c55a05e79a1b2c7dc57": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c950d9c74bf4afcb0b67b63ee0d2de7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_81de851fd71349c78e5fe841d233fea4",
       "IPY_MODEL_63129024f91c482da46c9ac7094577ce",
       "IPY_MODEL_b006448de2cb4508b42df4ecd3fe5f8b"
      ],
      "layout": "IPY_MODEL_6d5a67caec6f4d01bdfe8347aa673112"
     }
    },
    "20a0c56070a34a57bfbf5644790825e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e1582f9f01524c06a22292748b25faa3",
      "placeholder": "​",
      "style": "IPY_MODEL_ccc1e152e6d046edac82397ba22c147e",
      "value": " 424k/? [00:00&lt;00:00, 18.0MB/s]"
     }
    },
    "3b19fe70c21b4f6193aef5bdf4314c1d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3dae2255ce814f8d8e748b0bff6de5f6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e7a458b43e8477b8a6557b839699caf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_474ef1a806064bb49dcb34c223d4f95e",
       "IPY_MODEL_fc430d793af34d76b87cad97b499601c",
       "IPY_MODEL_6a1a78c312fc4557b63aeaa7f520265b"
      ],
      "layout": "IPY_MODEL_3b19fe70c21b4f6193aef5bdf4314c1d"
     }
    },
    "44dcec911c734f20836522fd428ed5a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_824389fafdcc4d6996da55884984b7fe",
      "max": 52554,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0d795275e8364fcba722c558bbac784d",
      "value": 52554
     }
    },
    "474ef1a806064bb49dcb34c223d4f95e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eebcc947f0424443b2333c62dc8fbf1e",
      "placeholder": "​",
      "style": "IPY_MODEL_0ff97cfa2fba4521bc5e0941595ad4b8",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
     }
    },
    "58243208c87c45c6be2b80fd42b0304f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b4a4e81d77894b97bbfbe758fa24caf3",
      "max": 52554,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_741779d00bd449d085d60253c531c515",
      "value": 52554
     }
    },
    "5de9bc5ac6594feab4fdae6f4f29f6ac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3dae2255ce814f8d8e748b0bff6de5f6",
      "placeholder": "​",
      "style": "IPY_MODEL_8d4ce5b4bdda45c985e80c00b91be7fa",
      "value": " 424k/? [00:00&lt;00:00, 17.5MB/s]"
     }
    },
    "5e026def0b3b455a8f9025eeb6ee1b92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9bc41f2f61244dc3ac3dfa88b1e8b271",
      "placeholder": "​",
      "style": "IPY_MODEL_dc297f854e054e32af42fe3a42195160",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
     }
    },
    "5f4aa45ac6c847889ad7391e397d3092": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "63129024f91c482da46c9ac7094577ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a8b0f82c6324bcd8929469301b3fa64",
      "max": 526251983,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f0cd440f98ab485f845a1e74d44b0426",
      "value": 526251983
     }
    },
    "63d92126944148d4b6bfca428b812c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a1a78c312fc4557b63aeaa7f520265b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9ee2ee31d6544832bdd1ac654cf70a8c",
      "placeholder": "​",
      "style": "IPY_MODEL_72b0a66f4e5c4af9b04f06245350a92b",
      "value": " 424k/? [00:00&lt;00:00, 8.95MB/s]"
     }
    },
    "6d5a67caec6f4d01bdfe8347aa673112": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "72b0a66f4e5c4af9b04f06245350a92b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "741779d00bd449d085d60253c531c515": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "778843fdc46243bc99c48bd8d83c6f69": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5e026def0b3b455a8f9025eeb6ee1b92",
       "IPY_MODEL_44dcec911c734f20836522fd428ed5a1",
       "IPY_MODEL_20a0c56070a34a57bfbf5644790825e3"
      ],
      "layout": "IPY_MODEL_0db1958bb8e64c0ea189244d76988db9"
     }
    },
    "81de851fd71349c78e5fe841d233fea4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc8a3a4cc9a64b78807e1993c45af211",
      "placeholder": "​",
      "style": "IPY_MODEL_f300528d14fe46849796cf17bad53fd9",
      "value": "Downloading https://huggingface.co/stanfordnlp/stanza-en/resolve/v1.10.0/models/default.zip: 100%"
     }
    },
    "824389fafdcc4d6996da55884984b7fe": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b7a6abb0c3c4483b62403eef3b28e78": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9effb41c74f54a73992070897522a8d1",
      "placeholder": "​",
      "style": "IPY_MODEL_b8096c686d2245c896576e3678dcdeab",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
     }
    },
    "8d4ce5b4bdda45c985e80c00b91be7fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9bc41f2f61244dc3ac3dfa88b1e8b271": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9c2586decd8e496bbe64056b58f5aa2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ee2ee31d6544832bdd1ac654cf70a8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9effb41c74f54a73992070897522a8d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a1d999f7545648d8bbf52fa83e4cd8bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a6de92e469474824a8d259d863ea90e4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b006448de2cb4508b42df4ecd3fe5f8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a6de92e469474824a8d259d863ea90e4",
      "placeholder": "​",
      "style": "IPY_MODEL_c177a3538ed641d795c1d9fb391fd8cb",
      "value": " 526M/526M [00:05&lt;00:00, 152MB/s]"
     }
    },
    "b249c7cd630a440a9d1384b0e78e5166": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c67e994f04db4045b32780660d85a77a",
      "placeholder": "​",
      "style": "IPY_MODEL_63d92126944148d4b6bfca428b812c92",
      "value": " 424k/? [00:00&lt;00:00, 1.16MB/s]"
     }
    },
    "b4a4e81d77894b97bbfbe758fa24caf3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8096c686d2245c896576e3678dcdeab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b99dc4d3a86a4c1cb4869a231fd014c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c177a3538ed641d795c1d9fb391fd8cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4f8807701bb481295481e23b6ce1322": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c2586decd8e496bbe64056b58f5aa2d",
      "max": 52554,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a1d999f7545648d8bbf52fa83e4cd8bd",
      "value": 52554
     }
    },
    "c67e994f04db4045b32780660d85a77a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cc8a3a4cc9a64b78807e1993c45af211": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccc1e152e6d046edac82397ba22c147e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d68ce4c5054d44f6aafc881ff0b1f7fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d815a3c5ee4d4e82a6273b5cbe3de72c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dcc18fb9003d465faa8f6565ee5ede5b",
       "IPY_MODEL_c4f8807701bb481295481e23b6ce1322",
       "IPY_MODEL_5de9bc5ac6594feab4fdae6f4f29f6ac"
      ],
      "layout": "IPY_MODEL_f38603b4db2c436c9bf590ae52d0f980"
     }
    },
    "dc297f854e054e32af42fe3a42195160": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcc18fb9003d465faa8f6565ee5ede5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_121ec3c89a334c55a05e79a1b2c7dc57",
      "placeholder": "​",
      "style": "IPY_MODEL_d68ce4c5054d44f6aafc881ff0b1f7fc",
      "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: "
     }
    },
    "e1582f9f01524c06a22292748b25faa3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eebcc947f0424443b2333c62dc8fbf1e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0cd440f98ab485f845a1e74d44b0426": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "f300528d14fe46849796cf17bad53fd9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f38603b4db2c436c9bf590ae52d0f980": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f58a69854c0a4f3cbc6ec9848c372694": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fc430d793af34d76b87cad97b499601c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5f4aa45ac6c847889ad7391e397d3092",
      "max": 52554,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b99dc4d3a86a4c1cb4869a231fd014c4",
      "value": 52554
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
